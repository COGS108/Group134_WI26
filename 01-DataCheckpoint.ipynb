{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "**Jerry Ying:** Conceptualization, Analysis, Methodology\n",
    "\n",
    "**Jimmy Ouyang:** Software, Visualization\n",
    "\n",
    "**Zack Chen:** Methodology, Background Research\n",
    "\n",
    "**Subika Haider:**  Analysis, Data Curation, Experimental Investigation\n",
    "\n",
    "**Jeremy Wei:** Project Administration, Data Curation\n",
    "\n",
    "**Everyone:** Writing – original draft, Writing – review & editing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Across NBA seasons 2016-17 to 2023-24, how well do a player’s basic box-score averages (points, rebounds, assists, steals, blocks) per game and selected advanced metrics (True-Shooting %, Player Efficiency Rating, Box Plus-Minus, and Win Shares per 48) explain the share of the salary cap the player earns in the following season?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NBA player salaries operate under a hard salary-cap system, which forces teams to divide a fixed pool of money across an entire roster. Because the cap changes from season to season, analysts often break salary figures down into share-of-cap terms to make contracts comparable across years. In this project, we ask whether commonly available performance data—basic box-score averages (points, rebounds, assists, steals, blocks) and selected advanced metrics (TS%, PER, BPM, and WS/48)—can explain how much of the cap a player earns in the following season. Framing the outcome this way helps factor out inflation effects from the analysis and keeps the focus on how teams appear to value on-court production when they set contracts.<a href=\"#ref1\"><sup>1</sup></a><a href=\"#ref2\"><sup>2</sup></a>\n",
    "\n",
    "Prior research in sports economics consistently finds that teams still pay heavily for visible box-score output, particularly scoring. Studies that model NBA salaries using traditional performance variables often show that points per game, minutes, and assists explain a substantial portion of salary variation, even after accounting for other factors. One applied analysis of NBA salary determinants finds that scoring remains one of the strongest predictors of pay, suggesting that front offices continue to price offensive volume into contracts even as analytics become more common.<a href=\"#ref3\"><sup>3</sup></a> These findings help set a baseline model up for our study, where box-score averages serve as the starting point for explaining salary share.\n",
    "\n",
    "At the same time, salary does not track box-score production perfectly. Contracts also factor in reputation, age, injury risk, positional demand, and the timing of free agency, all of which can pull pay away from pure statistical output. To fill in these gaps, analysts have increasingly brought advanced metrics into salary models in an effort to pick up value teams might otherwise miss. Papadaki and Tsagris (2020) model NBA salary share directly using machine-learning methods and show that performance variables can explain a meaningful share of compensation, while also demonstrating that salary outcomes remain noisy and difficult to pin down exactly.<a href=\"#ref4\"><sup>4</sup></a> Their work motivates our decision to focus on salary share and to compare how different sets of performance metrics explain it.\n",
    "\n",
    "More recent academic and student research has followed a similar path by combining traditional and advanced statistics to study player valuation and pay inequality. These projects often find that while stars dominate the top end of the salary distribution, certain efficient or high-impact role players appear underpaid relative to their statistical contribution. One such study categorizes players by role and shows that efficiency-based metrics help explain why some lower-usage players provide strong on-court value without receiving star-level contracts.<a href=\"#ref5\"><sup>5</sup></a> This body of work helps tie our hypothesis down: advanced metrics may not replace raw scoring as the strongest individual predictor, but they may improve overall model fit and reduce prediction error for non-star players.\n",
    "\n",
    "The advanced metrics used in this project are well established in public basketball analytics. TS% adjusts scoring efficiency by accounting for three-point shooting and free throws, while BPM and WS/48 aim to roll a player's total impact into a single number that adjusts for playing time and team context. These metrics attempt to build efficiency and impact into one measure, making them especially useful for evaluating players who log fewer minutes but perform well when on the floor.<a href=\"#ref1\"><sup>1</sup></a><a href=\"#ref6\"><sup>6</sup></a><a href=\"#ref7\"><sup>7</sup></a> By comparing a box-score-only model to one that folds these advanced metrics in, our project tests whether teams implicitly reward this type of efficiency when they set future salaries.\n",
    "\n",
    "Finally, this study contributes by examining multiple seasons (2016–17 through 2023–24) and by linking performance in one season to salary share in the next. This approach better reflects how front offices operate, since teams pay players based on expected future value rather than past production alone. By comparing stars and role players using the same model, we test whether advanced metrics narrow the difference between what players are paid and what their performance predicts, especially for players whose value is not well captured by per-game averages.\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h3>References</h3>\n",
    "\n",
    "<p><a name=\"ref1\"></a>1. <a href=\"#ref1\">^</a> NBA Stats Help Glossary — True Shooting Percentage (TS%) definition and formula. NBA.com. <b>https://www.nba.com/stats/help/glossary</b></p>\n",
    "\n",
    "<p><a name=\"ref2\"></a>2. <a href=\"#ref2\">^</a> Sports Reference / Basketball-Reference — WS/48 definition (and related advanced-stat glossary context). <b>https://www.basketball-reference.com/about/glossary.html</b></p>\n",
    "\n",
    "<p><a name=\"ref3\"></a>3. <a href=\"#ref3\">^</a> The Sport Journal (2015). \"Determinants of NBA Player Salaries.\" <b>https://thesportjournal.org/article/determinants-of-nba-player-salaries/</b></p>\n",
    "\n",
    "<p><a name=\"ref4\"></a>4. <a href=\"#ref4\">^</a> Papadaki, I. & Tsagris, M. (2020). \"Estimating NBA players' salary share according to their performance on court: A machine learning approach.\" arXiv. <b>https://arxiv.org/pdf/2007.14694</b></p>\n",
    "\n",
    "<p><a name=\"ref5\"></a>5. <a href=\"#ref5\">^</a> Riccardi, N. (2025). \"NBA player types and salaries: assessing the disparities in …\" (uses box-score + advanced stats to study salary patterns). Syracuse University SURFACE repository (PDF). <b>https://surface.syr.edu/cgi/viewcontent.cgi?article=1068&context=sportmanagement</b></p>\n",
    "\n",
    "<p><a name=\"ref6\"></a>6. <a href=\"#ref6\">^</a> Basketball-Reference — Box Plus/Minus (BPM) methodology overview. <b>https://www.basketball-reference.com/about/bpm2.html</b></p>\n",
    "\n",
    "<p><a name=\"ref7\"></a>7. <a href=\"#ref7\">^</a> Basketball-Reference — Win Shares primer (context for how WS is allocated and interpreted). <b>https://www.basketball-reference.com/about/ws.html</b></p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that both basic box-score averages and selected advanced metrics positively correlate with a player’s salary.\n",
    "\n",
    "While raw box-score (points, rebounds, assists, steals, blocks) averages will remain the strongest individual predictors of salary share (especially points per game), the inclusion of advanced metrics (such as win shares per 48 minutes) will increase the model’s overall R^2 and provide a more accurate valuation of players who receive less minutes but perform exceptional (i.e. high box-score statistics per minute, but relatively low box-score per game)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "## Dataset #1  \n",
    "\n",
    "**Dataset Name:** Basketball-Reference NBA Regular-Season Player Stats (2016-17 → 2023-24)  \n",
    "**Link:** <https://www.basketball-reference.com/leagues/>  \n",
    "**Number of observations:** ≈ 4 300 player-season rows  \n",
    " • raw scrape ≈ 4 800 rows (one row per player-team-season)  \n",
    " • ≈ 4 300 after keeping only the aggregated **TOT** row for traded players and dropping < 200-minute seasons  \n",
    "**Number of variables:** 55 raw columns; 15 retained for analysis  \n",
    "\n",
    "### Variables\n",
    "| B-Ref column | retained name | type | note |\n",
    "|--------------|--------------|------|------|\n",
    "| `Player` | `player` | string | accents/suffixes kept |\n",
    "| `Season` | `season` | int | 2024 for the 2023-24 season |\n",
    "| `Age` | `age` | int | age on Feb 1 |\n",
    "| `Tm` | `team` | category | franchise, **TOT** for multi-team seasons |\n",
    "| `G` | `games` | int | games played |\n",
    "| `MP` | `mp` | float | minutes played |\n",
    "| `PTS` | `pts` | float | points per game |\n",
    "| `TRB` | `trb` | float | rebounds per game |\n",
    "| `AST` | `ast` | float | assists per game |\n",
    "| `STL` | `stl` | float | steals per game |\n",
    "| `BLK` | `blk` | float | blocks per game |\n",
    "| `TS%` | `ts_pct` | float | true-shooting percentage (0-1) |\n",
    "| `PER` | `per` | float | Player Efficiency Rating (league avg = 15) |\n",
    "| `BPM` | `bpm` | float | Box Plus-Minus (per 100 poss.) |\n",
    "| `WS/48` | `ws_per48` | float | Win Shares per 48 minutes |\n",
    "\n",
    "Other scraped fields (e.g., eFG%, ORtg, USG%) were loaded but not used in the core model.\n",
    "\n",
    "### Shortcomings / quirks\n",
    "* Defensive positioning, on-ball vs off-ball value, and locker-room impact are not captured by box-score or advanced metrics.  \n",
    "* PER, BPM, WS/48 embed model assumptions and some team context; treat them as noisy performance proxies.  \n",
    "* Very low-minute players (< 200 MP) were dropped to avoid small-sample distortions; this slightly under-represents end-of-bench rookies and two-way call-ups.  \n",
    "* Mid-season trades create duplicate player rows in the raw scrape; those rows are collapsed to a single **TOT** entry per player-season.  \n",
    "* Age is delivered as string (`'28-123'` style) and must be parsed to an integer before use.\n",
    "\n",
    "> Source: Basketball-Reference, Sports Reference LLC.<a name=\"ref1\"></a><sup>1</sup>  \n",
    "> Advanced metric definitions: Basketball-Reference Glossary.<a name=\"ref2\"></a><sup>2</sup>\n",
    "\n",
    "## Dataset #2    \n",
    "\n",
    "**Dataset Name:** Spotrac NBA Contract & Salary Sheets (2016-17 → 2023-24)  \n",
    "**Link:** <https://www.spotrac.com/nba/contracts/>  \n",
    "**Number of observations:** ≈ 4 100 player-season rows  \n",
    " • ~5 000 raw rows (one row per player-team-season)  \n",
    " • ~4 100 after collapsing mid-season trades to a single “TOT” row  \n",
    "**Number of variables:** 33 raw columns; 10 retained for analysis  \n",
    "\n",
    "### Variables most relevant to our project\n",
    "| Spotrac column | retained name | type | note |\n",
    "|----------------|--------------|------|------|\n",
    "| `player` | `player` | string | roster name, accents kept |\n",
    "| `season` | `season` | int | 2024 for the 2023-24 season |\n",
    "| `team` | `team` | category | franchise at season start |\n",
    "| `age` | `age` | int | cast from string |\n",
    "| `salary_usd` | `salary_usd` | float | guaranteed salary |\n",
    "| `salary_cap` | `salary_cap` | float | NBA cap for that season |\n",
    "| — | `salary_share` | float | `salary_usd / salary_cap` |\n",
    "| `status` | `contract_type` | category | Rookie / Vet-Min / Two-Way / Max … |\n",
    "| `guaranteed` | `guaranteed` | float | guaranteed at signing (NA for 1-yr tables) |\n",
    "| `notes` | `notes` | string | incentives, options, etc. |\n",
    "\n",
    "Other monetary fields (`retained_salary`, `dead_cap`, `incentives`, …) are loaded but not used in the core analysis.\n",
    "\n",
    "### Shortcomings\n",
    "* Mid-season trades appear multiple times; collapse to one **TOT** row per player-season before aggregation.  \n",
    "* 10-day, Exhibit-10, and some two-way deals are not listed → lowest-salary fringe players are under-represented.  \n",
    "* `salary_usd` occasionally includes estimated incentives (flagged by “est.” in **notes**) introducing < 1 % error.  \n",
    "* Player names include accents, suffixes, and middle initials; normalize before joining with other datasets.  \n",
    "* `guaranteed` is absent in the single-season “Salary” tabs—scrape the *Contract & Payroll Details* table if you need it.\n",
    "\n",
    "> With these minor updates (column count = 33, `salary_cap` & `status` spelling, row counts) the description now reflects Spotrac’s current export structure for 2016-17 → 2023-24.\n",
    "\n",
    "- etc\n",
    "\n",
    "Each dataset deserves either a set of bullet points as above or a few sentences if you prefer that method.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, re\n",
    "\n",
    "df = pd.read_csv(\"NBA Contracts (1).csv\", quotechar='\"')\n",
    "\n",
    "# --- basic column tidy -------------------------------------------------\n",
    "df.columns = df.columns.str.strip()\n",
    "df[\"Team\"] = (df[\"Team                     Signed With\"]\n",
    "              .str.strip()\n",
    "              .replace(r\"\\s+\", \" \", regex=True))\n",
    "\n",
    "# numeric money\n",
    "money = lambda s: (s.str.replace(r\"[$,]\", \"\", regex=True).astype(float))\n",
    "df[\"Value\"] = money(df[\"Value\"])\n",
    "df[\"AAV\"]   = money(df[\"AAV\"])\n",
    "\n",
    "# season columns\n",
    "df[\"Start\"] = df[\"Start\"].astype(int)\n",
    "df[\"End\"]   = df[\"End\"].astype(int)\n",
    "\n",
    "# --- filter to seasons 2016-17 … 2023-24 -------------------------------\n",
    "LOW, HIGH = 2016, 2023          # last year of 2023-24 regular season\n",
    "mask = (df[\"Start\"] <= HIGH) & (df[\"End\"] >= LOW)\n",
    "df = df.loc[mask].copy()\n",
    "\n",
    "# you now have only contracts active at some point in 2016-17--2023-24\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# optional extras -------------------------------------------------------\n",
    "df = df.drop_duplicates()\n",
    "df[\"Player\"] = df[\"Player\"].str.strip()\n",
    "df[\"Pos\"]    = df[\"Pos\"].str.strip()\n",
    "\n",
    "# inspect\n",
    "print(df[[\"Player\",\"Start\",\"End\",\"Yrs\",\"Value\",\"AAV\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress:   0%|          | 0/16 [00:00<?, ?it/s]\n",
      "Downloading 23-24_basic.csv:   0%|          | 0.00/105k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:   6%|▋         | 1/16 [00:01<00:17,  1.16s/it]A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 23-24_basic.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 22-23_basic.csv:   0%|          | 0.00/97.2k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  12%|█▎        | 2/16 [00:03<00:27,  1.96s/it][A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 22-23_basic.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 21-22_basic.csv:   0%|          | 0.00/97.2k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  19%|█▉        | 3/16 [00:05<00:22,  1.71s/it][A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 21-22_basic.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 20-21_basic.csv:   0%|          | 0.00/97.2k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  25%|██▌       | 4/16 [00:06<00:17,  1.45s/it][A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 20-21_basic.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 19-20_basic.csv:   0%|          | 0.00/97.2k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  31%|███▏      | 5/16 [00:08<00:19,  1.75s/it][A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 19-20_basic.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 18-19_basic.csv:   0%|          | 0.00/97.2k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  38%|███▊      | 6/16 [00:09<00:15,  1.51s/it][A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 18-19_basic.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 17-18_basic.csv:   0%|          | 0.00/97.2k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  44%|████▍     | 7/16 [00:10<00:12,  1.42s/it][A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 17-18_basic.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 16-17_basic.csv:   0%|          | 0.00/97.2k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  50%|█████     | 8/16 [00:11<00:10,  1.34s/it][A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 16-17_basic.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 16-17_advanced.csv:   0%|          | 0.00/82.9k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  56%|█████▋    | 9/16 [00:13<00:09,  1.30s/it]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 16-17_advanced.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 17-18_advanced.csv:   0%|          | 0.00/91.5k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  62%|██████▎   | 10/16 [00:14<00:07,  1.28s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 17-18_advanced.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 18-19_advanced.csv:   0%|          | 0.00/98.0k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  69%|██████▉   | 11/16 [00:15<00:06,  1.24s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 18-19_advanced.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 19-20_advanced.csv:   0%|          | 0.00/90.5k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  75%|███████▌  | 12/16 [00:16<00:04,  1.23s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 19-20_advanced.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 20-21_advanced.csv:   0%|          | 0.00/98.2k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  81%|████████▏ | 13/16 [00:17<00:03,  1.21s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 20-21_advanced.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 21-22_advanced.csv:   0%|          | 0.00/111k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  88%|████████▊ | 14/16 [00:19<00:02,  1.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 21-22_advanced.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 22-23_advanced.csv:   0%|          | 0.00/94.4k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  94%|█████████▍| 15/16 [00:20<00:01,  1.22s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 22-23_advanced.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 23-24_advanced.csv:   0%|          | 0.00/102k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress: 100%|██████████| 16/16 [00:21<00:00,  1.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 23-24_advanced.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://drive.google.com/uc?id=1wGzBvkbvDsiSekr6o43thRt4noCNyuJN', 'filename' :'23-24_basic.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1oQo6DE5avgD9_GKHhcdvMctr-Gga4aWB', 'filename' :'22-23_basic.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1oQo6DE5avgD9_GKHhcdvMctr-Gga4aWB', 'filename' :'21-22_basic.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1Fx8oggm5LdPTnkdQ2PRHrEYMqvPby-e0', 'filename' :'20-21_basic.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1-Un6uX4A1EXZ_fqLI14GAW0qW8I5vM0a', 'filename' :'19-20_basic.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1W61fjUTIJBJjrFmSD_f4ZRM9IB6jVTDl', 'filename' :'18-19_basic.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=16rhHyQrbgyQM994j_wk0wyObQ0A16sp0', 'filename' :'17-18_basic.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1FW-Ce5yQhXuoIyTBRZu85a-89oLlZgwz', 'filename' :'16-17_basic.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1LGPII-4JWvgG2mBAyR_ytvoPDYbi5ono', 'filename' :'16-17_advanced.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1G6TePWw-7vQLAEWl18T2CXnD-QCwB-Vr', 'filename' :'17-18_advanced.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1lLRRmzXbrb38bfGfR9Hf3qm7EA5fLjoR', 'filename' :'18-19_advanced.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1ZjQC0J_3k2HSrx6Wwf0INUR_PRfeBb8Z', 'filename' :'19-20_advanced.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1PzhSv8cQyDP794dfI4wKZ9BKjlzw3AxJ', 'filename' :'20-21_advanced.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1A7I38hu9owHuZRh1EDg44uNOtaL-tTOi', 'filename' :'21-22_advanced.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=10NbM9Fz6pD1NiNe3tsefsQRzIeAZa1O0', 'filename' :'22-23_advanced.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1NqcN2sWDxlZZ2uJeWhbN2CF9YUYlsvQe', 'filename' :'23-24_advanced.csv'}\n",
    "    \n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basketball-Reference NBA Player Performance Dataset (2016–17 to 2023–24)\n",
    "\n",
    "This dataset contains season-level regular-season performance records for NBA players from 2016–17 through 2023–24. Each row represents one player in one season, with mid-season team changes collapsed into a single `TOT` record so each player-season appears only once. To reduce unstable small-sample observations, player-seasons with fewer than 200 total minutes were removed. After cleaning, the file includes a little over 4,300 player-season observations and 15 analysis-ready variables.\n",
    "\n",
    "The core production metrics are traditional per-game box-score stats: `PTS` (points), `TRB` (rebounds), `AST` (assists), `STL` (steals), and `BLK` (blocks). These are measured in events per game and capture scoring and all-around activity in a way that is intuitive and widely used by media, fans, and front offices. In practical terms, rotation players often score roughly 5–30 points per game, collect around 2–10 rebounds, and produce lower but meaningful rates in assists, steals, and blocks depending on role and position.\n",
    "\n",
    "The dataset also includes advanced efficiency and impact indicators. `TS%` (true shooting percentage) is a proportion from 0 to 1 that combines two-point shooting, three-point shooting, and free throws into one efficiency value; league average is usually near 0.57, values below 0.50 are typically inefficient, and values above 0.65 are elite. `PER` (player efficiency rating) is a pace-adjusted index normalized so league average is 15 each season; around 10 is replacement-level, 20–25 is typical All-Star range, and above 28 is often MVP-level. `BPM` (box plus-minus) is measured in points per 100 possessions versus league average, where 0 is average, +5 is All-Star caliber impact, and negative values suggest below-average contribution. `WS/48` (win shares per 48 minutes) estimates wins contributed per full game of playing time; league average is about 0.100 and values above roughly 0.230 are usually associated with top MVP candidates. `Age` is recorded as the player’s age on February 1 of the season, which aligns with common NBA roster and contract conventions.\n",
    "\n",
    "There are several important limitations. Advanced metrics like `PER`, `BPM`, and `WS/48` are model-based and depend on assumptions about box-score value, pace, and team context, so they should not be treated as pure ground truth. Excluding sub-200-minute players removes many short-term call-ups and two-way players, which can bias merged salary analyses upward by underrepresenting fringe minimum-salary roster spots. This file also includes regular season only, so postseason performance effects on market value are not captured. Finally, collapsing traded players to `TOT` improves uniqueness of player-season rows but removes team-level splits, which matters if the analysis needs franchise-specific performance-pay relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotrac NBA Contract and Salary Dataset (2016–17 to 2023–24)\n",
    "\n",
    "This dataset contains season-level NBA player compensation information compiled from Spotrac’s contract and payroll tables for the 2016–17 through 2023–24 seasons. In the raw extract, each row represents a player-team-season record, which produces about 5,000 rows because traded players can appear multiple times in the same year. For analysis, those split entries are collapsed into a single player-season `TOT` record, leaving roughly 4,100 unique player-season observations. The raw data includes 33 columns, with 10 primary variables retained for modeling compensation outcomes.\n",
    "\n",
    "The most important fields are `salary_usd` (guaranteed salary paid for that season, in U.S. dollars), `salary_cap` (the NBA salary cap for that season, in U.S. dollars), and `salary_share` (unitless proportion computed as `salary_usd / salary_cap`, which standardizes pay across cap environments). The dataset also includes `player` (name string), `season` (integer year code, where 2024 denotes the 2023–24 season), `team` (franchise identifier), `age` (integer), `contract_type` (categorical labels such as rookie-scale, veteran minimum, two-way, or max), `guaranteed` (guaranteed amount at signing, when available), and `notes` (text flags for incentives, options, or estimate tags). Together, these variables allow analysis of both absolute salary levels and relative cap burden, which is critical when comparing contracts across years with different league cap levels.\n",
    "\n",
    "There are several data-quality caveats to account for before inference. Mid-season trades create duplicate player-season rows unless explicitly collapsed to one `TOT` record. Some fringe contract types (for example, certain 10-day, Exhibit-10, or two-way arrangements) are not consistently captured, so the very bottom of the salary distribution may be underrepresented. In some cases, salary values include estimated incentives noted in `notes`, which introduces small measurement error (typically under 1%). Name formatting varies due to accents, suffixes, and middle initials, so normalization is necessary before merging with performance datasets like Basketball-Reference. Finally, `guaranteed` is often missing in single-season salary tabs and may need to be pulled from Spotrac’s full contract detail tables if guaranteed-at-signing analysis is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics\n",
    "\n",
    "Here is a [list of real world examples](https://deon.drivendata.org/examples/) for each item in the checklist that can refer to.\n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "\n",
    "    Although NBA salaries and performance statistics are in the public domain, our research involves the financial data of identifiable individuals. The principle of Beneficence dictates that our study should focus on aggregate market trends and systemic patterns rather than singling out specific athletes as \"outliers\" or \"overpaid.\" The data should be handled by us with professional decorum, ensuring our research serves to advance the understanding of sports economics and labor market efficiency without causing undue reputational harm to the individuals being studied.\n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    " - [X] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "\n",
    "    When analyzing the degree to which box-score and advanced metrics explain salary cap share, we have an ethical obligation to maintain \"epistemological integrity.\" This means clearly distinguishing between statistical explanation (correlation) and causation. Us researchers must avoid \"p-hacking\" or manipulating the data range (2016–2024) to find a higher $R^2$ value. Ethically, our findings must be presented transparently, even if the chosen metrics fail to explain a significant portion of the salary variance, to avoid creating a false narrative about how the NBA labor market operates.\n",
    "\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    " - [X] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    "\n",
    "    The selection of independent variables, specifically \"all-in\" metrics like PER, BPM, and Win Shares, carries an ethical weight. These metrics are human-made constructs with inherent biases (e.g., PER’s favoritism toward high-volume shooting). In our research, it is ethically necessary to acknowledge that using these metrics is an audit of the metrics themselves as much as it is an audit of the NBA’s salary structure. Us researchers must ensure the limitations of these mathematical formulas are disclosed so that the \"explanation\" provided is not mistaken for an objective truth about a player's total worth.\n",
    "\n",
    " - [X] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "    Ethical research requires a high degree of transparency regarding what the data cannot see. By focusing strictly on box scores and selected advanced stats, our study inherently ignores qualitative factors such as leadership, injury history, and defensive \"gravity.\" It is an ethical imperative to frame the results with the caveat that these metrics only capture a portion of a player's professional value. This prevents the research from being misinterpreted as a definitive guide for what a player \"should\" be paid, which could otherwise be used to unfairly minimize the value of unquantifiable contributions.\n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    "\n",
    "    Plan: We will implement a seasonal monitoring cycle to account for model drift. Because salary cap rules, positional value, and market behaviors shift annually, the model will be re-run each season. We will compare year-over-year performance, audit sample predictions, and generate a stability report to ensure the model remains accurate under new season conditions.\n",
    " - [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    "\n",
    "    Plan: We have established a response protocol for cases where a player may be reputationally harmed by model results (e.g., being publicly labeled as \"overpaid\"). We will evaluate these cases by auditing the specific inputs and logic that led to the label and will provide a mechanism to update the analysis if the harm stems from data inaccuracies or biased features.\n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    "\n",
    "    Plan: We have a \"kill switch\" and version control system in place. If errors are discovered in our analysis or visualizations after deployment, we can immediately roll back to a previous stable version or take the dashboard offline to prevent the spread of incorrect insights while we fix the underlying issue.\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "\n",
    "    Plan: To prevent misuse, all model outputs will include clear documentation and disclaimers. Specifically, we will explicitly state that the model identifies correlations, not causal relationships, to prevent stakeholders from assuming that changing one specific metric will certainly result in a higher salary. We will also monitor for \"shadow\" uses where the model might be used outside its intended scope (e.g., for injury prediction).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Communication\n",
    "- Primary channel: Discord (text + voice). Communicate via email if discord is not working.\n",
    "- Response window: ≤ 24 hrs Mon-Fri, ≤ 36 hrs on weekends.\n",
    "- Tone: “blunt-but-polite”. \n",
    "- Guidelines: Use I-statements, assume good intent, and ask clarifying questions. Whenever a conflict arises, focus on addressing the issue and not blaming other groupmates.\n",
    "\n",
    "### Meetings\n",
    "- Baseline: meet once per week. We can be flexible about meeting time as long as we meet the baseline. \n",
    "- More meetings shall be scheduled if necessary, and especially if closer to a deadline.\n",
    "- Meetings should preferably be in person. Online meetings shall be made if it happens late at night (e.g. after 9PM), or if an unexpected circumstance happens to prevent arrival on the designated location on time.\n",
    "\n",
    "### Decision-Making\n",
    "- Decisions should be made in consensus. \n",
    "- If no consensus after 10 min, decide by simple majority vote. If someone is unable to show up for a particular decision and does not offer one virtually, their vote is automatically rescinded.\n",
    "- When a deadline is < 24 hrs away, a decision can be made with the minimum of confirmation of 3 members. When a deadline is < 10 hrs away, a decision can be made with the minimum of confirmation of 2 members. When a deadline is < 2 hrs away, a decision can be made unilaterally given that 1) The decision-maker is fully confident that the decision will be more beneficial to the group than harmful; 2) The decision-maker will take full responsibility for the decision after it is made; 3) If other group members do not respond in a 30 minute window. \n",
    "- Regarding the previous point, no group member is allowed to make more than one unilateral decision. It should be treated as an absolute last-resort decision.\n",
    "\n",
    "### Deadlines\n",
    "- Internal deadlines are 48 hrs before the actual assignment deadline.\n",
    "- Members should agree on the final deliverable before the deadline. Otherwise, extra meeting(s) should be called as soon as possible to discuss refinements.\n",
    "\n",
    "### Conflict-Resolution Process\n",
    "- Calm yourself down. A decision shall only be made when every group member is not impacted by their emotions.\n",
    "- Think before you talk! Don’t talk just because you want to win the argument.\n",
    "- Step into the other party’s shoes. There are often overlaps even when there seems to be complete disagreements.\n",
    "- If absolutely necessary, talk to TAs about this issue and fix the problem together (last resort).\n",
    "- If a group member does work late/does not meet team expectations, directly speak with the relevant group member and help them out but reinforce team expectations. If this happens recurrently, reach out to TAs.\n",
    "\n",
    "### Inclusivity & Well-Being\n",
    "- In an online meeting: Cameras optional; mic required.\n",
    "- Allow religious holidays and accessibility needs.\n",
    "- No “stacking” late-night deadlines.\n",
    "\n",
    "### Agreement\n",
    "By signing below with their full name, each group member confirms they have read, understand, and agree to follow the team expectations.\n",
    "\n",
    "- Jimmy Ouyang\n",
    "- Jeremy Wei\n",
    "- Zack Chen\n",
    "- Subika Haider\n",
    "- Jerry Ying\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Meeting Schedule\n",
    "\n",
    "| Meeting Date | Meeting Time | Completed Before Meeting | Discuss at Meeting | Status |\n",
    "|-------------|--------------|--------------------------|-------------------|--------|\n",
    "| 1/26/2026 | 17:00 | Determine the best form of communication; read & think about COGS 108 project expectations; review previous COGS 108 projects | Assign group-member tasks; review and discuss selected COGS 108 projects; analyze and evaluate the projects | ✅ |\n",
    "| 2/3/2026  | 21:30 | Read through COGS108 project-proposal documents and critically analyze them | Discuss ideal dataset(s) and ethics; draft project proposal; assign group-member tasks | ✅ |\n",
    "| 2/4/2026  | 13:00 | Members complete assigned tasks; finish first draft of project proposal | Discuss and complete final project proposal | ✅ |\n",
    "| 2/8/2026  | 21:00 | N/A | Discuss and confirm tasks assigned to each member until next progress check | ✅ |\n",
    "| 2/11/2026 | 13:30 | Group members make progress on assigned tasks | Progress check and peer review | ✅ |\n",
    "| 2/17/2026 | 21:00 | Group members complete Checkpoint 1 requirements | Discuss and finalize Checkpoint 1 document; confirm tasks until next progress check | ✅ |\n",
    "| 2/18/2026 | 13:00 | Group members finalize Checkpoint 1 requirements | Discuss and finalize Checkpoint 1 document; confirm tasks until next progress check | ⏳ |\n",
    "| 2/25/2026 | 13:00 | Progress on data import,wrangling, and EDA | Progress check and peer review; review/edit wrangling & EDA; discuss analysis plan | ⏳ |\n",
    "| 3/3/2026  | 13:00 | Finalize wrangling, EDA, and analysis | Discuss and finalize Checkpoint 2 document; complete project check-in; assign next tasks | ⏳ |\n",
    "| 3/6/2026  | 13:00 | Complete analysis;draft results, conclusion, and discussion | Progress check and peer review; discuss and edit full project | ⏳ |\n",
    "| 3/13/2026 | 13:00 | Progress on assigned tasks | Progress check and peer review | ⏳ |\n",
    "| 3/16/2026 | 13:00 | Group members finish assigned parts | Discuss final project and video; finalize team-evaluation survey | ⏳ |\n",
    "| 3/18/2026 | Before 11:59 | Video and project refined | Final project and video check; submit project on time | ⏳ |\n",
    "\n",
    "---\n",
    "\n",
    "### Role & Responsibility Matrix\n",
    "\n",
    "| # | Tasks | Lead Contributor | Backup contributor | Support | Notes for implementation|\n",
    "|---|--------------------|----------|------------|-------------|-----------|\n",
    "| 1 | Project administration & timeline tracking | Jeremy | Jerry | Everyone | Sets agendas, posts minutes, updates Kanban, reminds team of deadlines. |\n",
    "| 2 | Conceptualization & research question | Jerry | Zack | Everyone | Frames hypothesis, defines variables, keeps scope realistic. |\n",
    "| 3 | Background / related-work section | Zack | Jerry | Everyone | Gathers literature and comparable projects; drafts background text. |\n",
    "| 4 | Data sourcing & ethics checklist | Subika | Jeremy | Zack | Locates raw datasets, documents licenses/IRB issues, stores files in `/data/raw`. |\n",
    "| 5 | Data curation & wrangling notebooks | Subika | Jimmy | Jeremy | Cleans, merges, and outputs tidy `player_season.csv`. |\n",
    "| 6 | Analysis & modeling notebooks | Jerry | Subika | Jimmy | Builds regression models, checks assumptions, saves results tables/figures. |\n",
    "| 7 | Visualization (EDA + final figs) | Jimmy | Jerry | Subika | Creates clear, colour-blind-friendly plots; exports to `figs/`. |\n",
    "| 8 | Software engineering / GitOps | Jimmy | Jeremy | Everyone | Maintains repo structure, code style, CI tests, branch protection. |\n",
    "| 9 | Writing – results&discussion | Jerry | Subika | Zack | Interprets coefficients, links to background, notes limitations. |\n",
    "|10 | Writing – abstract, intro, methods | Zack | Jerry | Jeremy | Ensures consistency with background & data sections. |\n",
    "|11 | Editing & proof-reading pass | Everyone | – | – | Two-person review rule before any section is marked “Done.” |\n",
    "|12 | Video script & slide deck | Jeremy | Jimmy | Everyone | 2-min script locked by 3/13; rehearsals in 3/16 meeting. |\n",
    "|13 | Video recording & post-production | Jimmy | Jeremy | Zack | Uses OBS + iMovie/DaVinci; exports MP4 < 100 MB. |\n",
    "|14 | Final QA&submission to Gradescope | Jeremy | Jimmy | Everyone | Runs notebook end-to-end, checks links, submits by 3/18 23:59. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits\n",
    "We used AI tools to help with writing and brainstorming ideas. All work is cross-checked by group members."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
