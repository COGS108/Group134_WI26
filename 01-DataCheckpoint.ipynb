{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "**Jerry Ying:** Conceptualization, Analysis, Methodology\n",
    "\n",
    "**Jimmy Ouyang:** Software, Visualization\n",
    "\n",
    "**Zack Chen:** Methodology, Background Research\n",
    "\n",
    "**Subika Haider:**  Analysis, Data Curation, Experimental Investigation\n",
    "\n",
    "**Jeremy Wei:** Project Administration, Data Curation\n",
    "\n",
    "**Everyone:** Writing – original draft, Writing – review & editing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Across NBA seasons 2016-17 to 2023-24, how well do a player’s basic box-score averages (points, rebounds, assists, steals, blocks) per game and selected advanced metrics (True-Shooting %, Player Efficiency Rating, Box Plus-Minus, and Win Shares per 48) explain the share of the salary cap the player earns in the following season?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NBA player salaries operate under a hard salary-cap system, which forces teams to divide a fixed pool of money across an entire roster. Because the cap changes from season to season, analysts often break salary figures down into share-of-cap terms to make contracts comparable across years. In this project, we ask whether commonly available performance data—basic box-score averages (points, rebounds, assists, steals, blocks) and selected advanced metrics (TS%, PER, BPM, and WS/48)—can explain how much of the cap a player earns in the following season. Framing the outcome this way helps factor out inflation effects from the analysis and keeps the focus on how teams appear to value on-court production when they set contracts.<a href=\"#ref1\"><sup>1</sup></a><a href=\"#ref2\"><sup>2</sup></a>\n",
    "\n",
    "Prior research in sports economics consistently finds that teams still pay heavily for visible box-score output, particularly scoring. Studies that model NBA salaries using traditional performance variables often show that points per game, minutes, and assists explain a substantial portion of salary variation, even after accounting for other factors. One applied analysis of NBA salary determinants finds that scoring remains one of the strongest predictors of pay, suggesting that front offices continue to price offensive volume into contracts even as analytics become more common.<a href=\"#ref3\"><sup>3</sup></a> These findings help set a baseline model up for our study, where box-score averages serve as the starting point for explaining salary share.\n",
    "\n",
    "At the same time, salary does not track box-score production perfectly. Contracts also factor in reputation, age, injury risk, positional demand, and the timing of free agency, all of which can pull pay away from pure statistical output. To fill in these gaps, analysts have increasingly brought advanced metrics into salary models in an effort to pick up value teams might otherwise miss. Papadaki and Tsagris (2020) model NBA salary share directly using machine-learning methods and show that performance variables can explain a meaningful share of compensation, while also demonstrating that salary outcomes remain noisy and difficult to pin down exactly.<a href=\"#ref4\"><sup>4</sup></a> Their work motivates our decision to focus on salary share and to compare how different sets of performance metrics explain it.\n",
    "\n",
    "More recent academic and student research has followed a similar path by combining traditional and advanced statistics to study player valuation and pay inequality. These projects often find that while stars dominate the top end of the salary distribution, certain efficient or high-impact role players appear underpaid relative to their statistical contribution. One such study categorizes players by role and shows that efficiency-based metrics help explain why some lower-usage players provide strong on-court value without receiving star-level contracts.<a href=\"#ref5\"><sup>5</sup></a> This body of work helps tie our hypothesis down: advanced metrics may not replace raw scoring as the strongest individual predictor, but they may improve overall model fit and reduce prediction error for non-star players.\n",
    "\n",
    "The advanced metrics used in this project are well established in public basketball analytics. TS% adjusts scoring efficiency by accounting for three-point shooting and free throws, while BPM and WS/48 aim to roll a player's total impact into a single number that adjusts for playing time and team context. These metrics attempt to build efficiency and impact into one measure, making them especially useful for evaluating players who log fewer minutes but perform well when on the floor.<a href=\"#ref1\"><sup>1</sup></a><a href=\"#ref6\"><sup>6</sup></a><a href=\"#ref7\"><sup>7</sup></a> By comparing a box-score-only model to one that folds these advanced metrics in, our project tests whether teams implicitly reward this type of efficiency when they set future salaries.\n",
    "\n",
    "Finally, this study contributes by examining multiple seasons (2016–17 through 2023–24) and by linking performance in one season to salary share in the next. This approach better reflects how front offices operate, since teams pay players based on expected future value rather than past production alone. By comparing stars and role players using the same model, we test whether advanced metrics narrow the difference between what players are paid and what their performance predicts, especially for players whose value is not well captured by per-game averages.\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h3>References</h3>\n",
    "\n",
    "<p><a name=\"ref1\"></a>1. <a href=\"#ref1\">^</a> NBA Stats Help Glossary — True Shooting Percentage (TS%) definition and formula. NBA.com. <b>https://www.nba.com/stats/help/glossary</b></p>\n",
    "\n",
    "<p><a name=\"ref2\"></a>2. <a href=\"#ref2\">^</a> Sports Reference / Basketball-Reference — WS/48 definition (and related advanced-stat glossary context). <b>https://www.basketball-reference.com/about/glossary.html</b></p>\n",
    "\n",
    "<p><a name=\"ref3\"></a>3. <a href=\"#ref3\">^</a> The Sport Journal (2015). \"Determinants of NBA Player Salaries.\" <b>https://thesportjournal.org/article/determinants-of-nba-player-salaries/</b></p>\n",
    "\n",
    "<p><a name=\"ref4\"></a>4. <a href=\"#ref4\">^</a> Papadaki, I. & Tsagris, M. (2020). \"Estimating NBA players' salary share according to their performance on court: A machine learning approach.\" arXiv. <b>https://arxiv.org/pdf/2007.14694</b></p>\n",
    "\n",
    "<p><a name=\"ref5\"></a>5. <a href=\"#ref5\">^</a> Riccardi, N. (2025). \"NBA player types and salaries: assessing the disparities in …\" (uses box-score + advanced stats to study salary patterns). Syracuse University SURFACE repository (PDF). <b>https://surface.syr.edu/cgi/viewcontent.cgi?article=1068&context=sportmanagement</b></p>\n",
    "\n",
    "<p><a name=\"ref6\"></a>6. <a href=\"#ref6\">^</a> Basketball-Reference — Box Plus/Minus (BPM) methodology overview. <b>https://www.basketball-reference.com/about/bpm2.html</b></p>\n",
    "\n",
    "<p><a name=\"ref7\"></a>7. <a href=\"#ref7\">^</a> Basketball-Reference — Win Shares primer (context for how WS is allocated and interpreted). <b>https://www.basketball-reference.com/about/ws.html</b></p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that both basic box-score averages and selected advanced metrics positively correlate with a player’s salary.\n",
    "\n",
    "While raw box-score (points, rebounds, assists, steals, blocks) averages will remain the strongest individual predictors of salary share (especially points per game), the inclusion of advanced metrics (such as win shares per 48 minutes) will increase the model’s overall R^2 and provide a more accurate valuation of players who receive less minutes but perform exceptional (i.e. high box-score statistics per minute, but relatively low box-score per game)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "## Dataset #1  \n",
    "\n",
    "**Dataset Name:** Basketball-Reference NBA Regular-Season Player Stats (2016-17 → 2023-24)  \n",
    "**Link:** <https://www.basketball-reference.com/leagues/>  \n",
    "**Number of observations:** ≈ 4 300 player-season rows  \n",
    " • raw scrape ≈ 4 800 rows (one row per player-team-season)  \n",
    " • ≈ 4 300 after keeping only the aggregated **TOT** row for traded players and dropping < 200-minute seasons  \n",
    "**Number of variables:** 55 raw columns; 15 retained for analysis  \n",
    "\n",
    "### Variables\n",
    "| B-Ref column | retained name | type | note |\n",
    "|--------------|--------------|------|------|\n",
    "| `Player` | `player` | string | accents/suffixes kept |\n",
    "| `Season` | `season` | int | 2024 for the 2023-24 season |\n",
    "| `Age` | `age` | int | age on Feb 1 |\n",
    "| `G` | `games` | int | games played |\n",
    "| `PTS` | `pts` | float | points per game |\n",
    "| `TRB` | `trb` | float | rebounds per game |\n",
    "| `AST` | `ast` | float | assists per game |\n",
    "| `STL` | `stl` | float | steals per game |\n",
    "| `BLK` | `blk` | float | blocks per game |\n",
    "| `TS%` | `ts_pct` | float | true-shooting percentage (0-1) |\n",
    "| `PER` | `per` | float | Player Efficiency Rating (league avg = 15) |\n",
    "| `BPM` | `bpm` | float | Box Plus-Minus (per 100 poss.) |\n",
    "| `WS/48` | `ws_per48` | float | Win Shares per 48 minutes |\n",
    "\n",
    "Other scraped fields (e.g., eFG%, ORtg, USG%) were loaded but not used in the core model.\n",
    "\n",
    "### Shortcomings\n",
    "* Defensive positioning, on-ball vs off-ball value, and locker-room impact are not captured by box-score or advanced metrics.  \n",
    "* PER, BPM, WS/48 embed model assumptions and some team context; treat them as noisy performance proxies.  \n",
    "* Mid-season trades create duplicate player rows in the raw scrape; those rows are collapsed to a single **TOT** entry per player-season.  \n",
    "* Age is delivered as string (`'28-123'` style) and must be parsed to an integer before use.\n",
    "\n",
    "> Source: Basketball-Reference, Sports Reference LLC.<a name=\"ref1\"></a><sup>1</sup>  \n",
    "> Advanced metric definitions: Basketball-Reference Glossary.<a name=\"ref2\"></a><sup>2</sup>\n",
    "\n",
    "## Dataset #2    \n",
    "\n",
    "**Dataset Name:** Spotrac NBA Contract & Salary Sheets (2016-17 → 2023-24)  \n",
    "**Link:** <https://www.spotrac.com/nba/contracts/>  \n",
    "**Number of observations:** ≈ 4 100 player-season rows  \n",
    " • ~5 000 raw rows (one row per player-team-season)  \n",
    " • ~4 100 after collapsing mid-season trades to a single “TOT” row  \n",
    "**Number of variables:** 33 raw columns; 10 retained for analysis  \n",
    "\n",
    "### Variables most relevant to our project\n",
    "| Spotrac column | retained name | type | note |\n",
    "|----------------|--------------|------|------|\n",
    "| `player` | `player` | string | roster name, accents kept |\n",
    "| `season` | `season` | int | 2024 for the 2023-24 season |\n",
    "| `age` | `age` | int | cast from string |\n",
    "| `salary_usd` | `salary_usd` | float | guaranteed salary |\n",
    "| `salary_cap` | `salary_cap` | float | NBA cap for that season |\n",
    "| — | `salary_share` | float | `salary_usd / salary_cap` |\n",
    "| `status` | `contract_type` | category | Rookie / Vet-Min / Two-Way / Max … |\n",
    "| `guaranteed` | `guaranteed` | float | guaranteed at signing (NA for 1-yr tables) |\n",
    "| `notes` | `notes` | string | incentives, options, etc. |\n",
    "\n",
    "Other monetary fields (`retained_salary`, `dead_cap`, `incentives`, …) are loaded but not used in the core analysis.\n",
    "\n",
    "### Shortcomings\n",
    "* Mid-season trades appear multiple times; collapse to one **TOT** row per player-season before aggregation.  \n",
    "* 10-day, Exhibit-10, and some two-way deals are not listed → lowest-salary fringe players are under-represented.  \n",
    "* `salary_usd` occasionally includes estimated incentives (flagged by “est.” in **notes**) introducing < 1 % error.  \n",
    "* Player names include accents, suffixes, and middle initials; normalize before joining with other datasets.  \n",
    "* `guaranteed` is absent in the single-season “Salary” tabs—scrape the *Contract & Payroll Details* table if you need it.\n",
    "\n",
    "> With these minor updates (column count = 33, `salary_cap` & `status` spelling, row counts) the description now reflects Spotrac’s current export structure for 2016-17 → 2023-24.\n",
    "\n",
    "- etc\n",
    "\n",
    "Each dataset deserves either a set of bullet points as above or a few sentences if you prefer that method.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress:   0%|          | 0/17 [00:00<?, ?it/s]\n",
      "Downloading 23-24_basic.csv:   0%|          | 0.00/103k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:   6%|▌         | 1/17 [00:01<00:22,  1.40s/it]A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 23-24_basic.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 22-23_basic.csv:   0%|          | 0.00/96.0k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  12%|█▏        | 2/17 [00:02<00:17,  1.18s/it][A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 22-23_basic.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 21-22_basic.csv:   0%|          | 0.00/112k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  18%|█▊        | 3/17 [00:03<00:16,  1.19s/it]A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 21-22_basic.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 20-21_basic.csv:   0%|          | 0.00/99.6k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  24%|██▎       | 4/17 [00:04<00:15,  1.19s/it][A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 20-21_basic.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 19-20_basic.csv:   0%|          | 0.00/91.9k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  29%|██▉       | 5/17 [00:05<00:14,  1.18s/it][A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 19-20_basic.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 18-19_basic.csv:   0%|          | 0.00/99.4k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  35%|███▌      | 6/17 [00:07<00:12,  1.15s/it][A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 18-19_basic.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 17-18_basic.csv:   0%|          | 0.00/92.5k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  41%|████      | 7/17 [00:08<00:11,  1.17s/it][A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 17-18_basic.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 16-17_basic.csv:   0%|          | 0.00/84.0k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  47%|████▋     | 8/17 [00:09<00:10,  1.15s/it][A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 16-17_basic.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 16-17_advanced.csv:   0%|          | 0.00/82.9k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  53%|█████▎    | 9/17 [00:10<00:08,  1.12s/it]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 16-17_advanced.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 17-18_advanced.csv:   0%|          | 0.00/91.5k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  59%|█████▉    | 10/17 [00:12<00:10,  1.47s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 17-18_advanced.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 18-19_advanced.csv:   0%|          | 0.00/98.0k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  65%|██████▍   | 11/17 [00:13<00:08,  1.40s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 18-19_advanced.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 19-20_advanced.csv:   0%|          | 0.00/90.5k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  71%|███████   | 12/17 [00:15<00:06,  1.33s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 19-20_advanced.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 20-21_advanced.csv:   0%|          | 0.00/98.2k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  76%|███████▋  | 13/17 [00:16<00:05,  1.26s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 20-21_advanced.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 21-22_advanced.csv:   0%|          | 0.00/111k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  82%|████████▏ | 14/17 [00:17<00:03,  1.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 21-22_advanced.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 22-23_advanced.csv:   0%|          | 0.00/94.4k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  88%|████████▊ | 15/17 [00:18<00:02,  1.16s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 22-23_advanced.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 23-24_advanced.csv:   0%|          | 0.00/102k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  94%|█████████▍| 16/17 [00:19<00:01,  1.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 23-24_advanced.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading NBA_Contracts.csv:   0%|          | 0.00/892k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading NBA_Contracts.csv:  43%|████▎     | 383k/892k [00:00<00:00, 3.80MB/s]\u001b[A\n",
      "Overall Download Progress: 100%|██████████| 17/17 [00:21<00:00,  1.24s/it]       \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: NBA_Contracts.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://drive.google.com/uc?id=1M7IKhsyZ-7yaJPa1yuVDY1LEo6QOjq09', 'filename' :'23-24_basic.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1tbl3IVr4zevJmpQzQXGnnlTUJ6bRnxmw', 'filename' :'22-23_basic.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1MMrKGYONPPg7mFoA-1ZV1r_8soB9MygG', 'filename' :'21-22_basic.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1hjK1-8MPjDDa0dbPLLOcSLop0A9qE60k', 'filename' :'20-21_basic.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1vMkENmb3b_2HlZVqNp-hJXwN-UaHWi85', 'filename' :'19-20_basic.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1BRKIVPu1kMpks7KmM2PznmYn7qgpqnpV', 'filename' :'18-19_basic.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1p0HsVwCvrJVjazWEQIAVsKnEBW35im_F', 'filename' :'17-18_basic.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1Y_lSjyeL2Gox5-4lV2TTNiLgkdD0yMnG', 'filename' :'16-17_basic.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1LGPII-4JWvgG2mBAyR_ytvoPDYbi5ono', 'filename' :'16-17_advanced.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1G6TePWw-7vQLAEWl18T2CXnD-QCwB-Vr', 'filename' :'17-18_advanced.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1lLRRmzXbrb38bfGfR9Hf3qm7EA5fLjoR', 'filename' :'18-19_advanced.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1ZjQC0J_3k2HSrx6Wwf0INUR_PRfeBb8Z', 'filename' :'19-20_advanced.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1PzhSv8cQyDP794dfI4wKZ9BKjlzw3AxJ', 'filename' :'20-21_advanced.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1A7I38hu9owHuZRh1EDg44uNOtaL-tTOi', 'filename' :'21-22_advanced.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=10NbM9Fz6pD1NiNe3tsefsQRzIeAZa1O0', 'filename' :'22-23_advanced.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1NqcN2sWDxlZZ2uJeWhbN2CF9YUYlsvQe', 'filename' :'23-24_advanced.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?id=1AFkBnfUjT6FWgDJgT7cGeHvpFn13J6--', 'filename' :'NBA_Contracts.csv'}\n",
    "    \n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basketball-Reference NBA Player Performance Dataset (2016–17 to 2023–24)\n",
    "\n",
    "This dataset contains season-level regular-season performance records for NBA players from 2016–17 through 2023–24. Each row represents one player in one season, with mid-season team changes collapsed into a single `TOT` record so each player-season appears only once. To reduce unstable small-sample observations, player-seasons with fewer than 200 total minutes were removed. After cleaning, the file includes a little over 4,300 player-season observations and 15 analysis-ready variables.\n",
    "\n",
    "The core production metrics are traditional per-game box-score stats: `PTS` (points), `TRB` (rebounds), `AST` (assists), `STL` (steals), and `BLK` (blocks). These are measured in events per game and capture scoring and all-around activity in a way that is intuitive and widely used by media, fans, and front offices. In practical terms, rotation players often score roughly 5–30 points per game, collect around 2–10 rebounds, and produce lower but meaningful rates in assists, steals, and blocks depending on role and position.\n",
    "\n",
    "The dataset also includes advanced efficiency and impact indicators. `TS%` (true shooting percentage) is a proportion from 0 to 1 that combines two-point shooting, three-point shooting, and free throws into one efficiency value; league average is usually near 0.57, values below 0.50 are typically inefficient, and values above 0.65 are elite. `PER` (player efficiency rating) is a pace-adjusted index normalized so league average is 15 each season; around 10 is replacement-level, 20–25 is typical All-Star range, and above 28 is often MVP-level. `BPM` (box plus-minus) is measured in points per 100 possessions versus league average, where 0 is average, +5 is All-Star caliber impact, and negative values suggest below-average contribution. `WS/48` (win shares per 48 minutes) estimates wins contributed per full game of playing time; league average is about 0.100 and values above roughly 0.230 are usually associated with top MVP candidates. `Age` is recorded as the player’s age on February 1 of the season, which aligns with common NBA roster and contract conventions.\n",
    "\n",
    "There are several important limitations. Advanced metrics like `PER`, `BPM`, and `WS/48` are model-based and depend on assumptions about box-score value, pace, and team context, so they should not be treated as pure ground truth. Excluding sub-200-minute players removes many short-term call-ups and two-way players, which can bias merged salary analyses upward by underrepresenting fringe minimum-salary roster spots. This file also includes regular season only, so postseason performance effects on market value are not captured. Finally, collapsing traded players to `TOT` improves uniqueness of player-season rows but removes team-level splits, which matters if the analysis needs franchise-specific performance-pay relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code was originally implemented by us, but we were only able to import the data for one season. We tried joining the datasets\n",
    "#but didn't work. Hence, we used AI to assist us on loading the data to our collective dataframe that we can later use. \n",
    "import pandas as pd\n",
    "\n",
    "# build basic/advanced lists from your existing datafiles list\n",
    "basic_stats_files = [f for f in datafiles if f[\"filename\"].endswith(\"_basic.csv\")]\n",
    "advanced_stats_files = [f for f in datafiles if f[\"filename\"].endswith(\"_advanced.csv\")]\n",
    "\n",
    "# match by season key (e.g., \"23-24\")\n",
    "basic_by_season = {f[\"filename\"].split(\"_\")[0]: f for f in basic_stats_files}\n",
    "adv_by_season = {f[\"filename\"].split(\"_\")[0]: f for f in advanced_stats_files}\n",
    "\n",
    "def pick_col(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def one_row_per_player(df):\n",
    "    out = df.copy()\n",
    "\n",
    "    # remove repeated header rows\n",
    "    if \"Rk\" in out.columns:\n",
    "        out = out[out[\"Rk\"].astype(str).str.lower() != \"rk\"].copy()\n",
    "\n",
    "    # prefer TOT row when available; otherwise highest MP\n",
    "    if \"Tm\" in out.columns:\n",
    "        out[\"Tm\"] = out[\"Tm\"].astype(str).str.upper().str.strip()\n",
    "        has_tot = out.groupby(\"Player\")[\"Tm\"].transform(lambda s: (s == \"TOT\").any())\n",
    "        out = out[(~has_tot) | (out[\"Tm\"] == \"TOT\")].copy()\n",
    "\n",
    "    if \"MP\" in out.columns:\n",
    "        out[\"_mp_num\"] = pd.to_numeric(out[\"MP\"], errors=\"coerce\").fillna(-1)\n",
    "    else:\n",
    "        out[\"_mp_num\"] = -1\n",
    "\n",
    "    out = out.sort_values([\"Player\", \"_mp_num\"], ascending=[True, False])\n",
    "    out = out.drop_duplicates(subset=[\"Player\"], keep=\"first\")\n",
    "    out = out.drop(columns=[\"_mp_num\"], errors=\"ignore\")\n",
    "    return out\n",
    "\n",
    "dfs = []\n",
    "prefix = \"data/00-raw/\"\n",
    "\n",
    "for season_key in sorted(set(basic_by_season) & set(adv_by_season), key=lambda s: int(s.split(\"-\")[0])):\n",
    "    df_basic = pd.read_csv(prefix + basic_by_season[season_key][\"filename\"])\n",
    "    df_adv = pd.read_csv(prefix + adv_by_season[season_key][\"filename\"])\n",
    "\n",
    "    df_basic = one_row_per_player(df_basic)\n",
    "    df_adv = one_row_per_player(df_adv)\n",
    "\n",
    "    # merge on stable keys\n",
    "    merge_keys = [c for c in [\"Player\", \"Age\"] if c in df_basic.columns and c in df_adv.columns]\n",
    "    combined = pd.merge(df_basic, df_adv, on=merge_keys, how=\"inner\", suffixes=(\"_basic\", \"_adv\"))\n",
    "\n",
    "    # build normalized output columns robustly\n",
    "    player_col = pick_col(combined, [\"Player\"])\n",
    "    age_col = pick_col(combined, [\"Age\"])\n",
    "    team_col = pick_col(combined, [\"Tm_basic\", \"Tm\", \"Team_basic\", \"Team\"])\n",
    "    games_col = pick_col(combined, [\"G_basic\", \"G\"])\n",
    "    mp_col = pick_col(combined, [\"MP_basic\", \"MP\"])\n",
    "    pts_col = pick_col(combined, [\"PTS_basic\", \"PTS\"])\n",
    "    trb_col = pick_col(combined, [\"TRB_basic\", \"TRB\"])\n",
    "    ast_col = pick_col(combined, [\"AST_basic\", \"AST\"])\n",
    "    stl_col = pick_col(combined, [\"STL_basic\", \"STL\"])\n",
    "    blk_col = pick_col(combined, [\"BLK_basic\", \"BLK\"])\n",
    "    ts_col = pick_col(combined, [\"TS%_adv\", \"TS%\"])\n",
    "    per_col = pick_col(combined, [\"PER_adv\", \"PER\"])\n",
    "    bpm_col = pick_col(combined, [\"BPM_adv\", \"BPM\"])\n",
    "    ws48_col = pick_col(combined, [\"WS/48_adv\", \"WS/48\"])\n",
    "\n",
    "    panel = pd.DataFrame({\n",
    "        \"player\": combined[player_col],\n",
    "        \"season\": season_key,\n",
    "        \"age\": combined[age_col],\n",
    "        \"team\": combined[team_col] if team_col else pd.NA,\n",
    "        \"games\": combined[games_col] if games_col else pd.NA,\n",
    "        \"mp\": combined[mp_col] if mp_col else pd.NA,\n",
    "        \"pts\": combined[pts_col] if pts_col else pd.NA,\n",
    "        \"trb\": combined[trb_col] if trb_col else pd.NA,\n",
    "        \"ast\": combined[ast_col] if ast_col else pd.NA,\n",
    "        \"stl\": combined[stl_col] if stl_col else pd.NA,\n",
    "        \"blk\": combined[blk_col] if blk_col else pd.NA,\n",
    "        \"ts_pct\": combined[ts_col] if ts_col else pd.NA,\n",
    "        \"per\": combined[per_col] if per_col else pd.NA,\n",
    "        \"bpm\": combined[bpm_col] if bpm_col else pd.NA,\n",
    "        \"ws_per48\": combined[ws48_col] if ws48_col else pd.NA,\n",
    "    })\n",
    "\n",
    "    dfs.append(panel)\n",
    "\n",
    "df_combined = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_pct      25\n",
      "age          8\n",
      "team         8\n",
      "games        8\n",
      "mp           8\n",
      "pts          8\n",
      "trb          8\n",
      "ast          8\n",
      "stl          8\n",
      "blk          8\n",
      "per          8\n",
      "bpm          8\n",
      "ws_per48     8\n",
      "player       0\n",
      "season       0\n",
      "dtype: int64\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "# This outputs the null counts per column\n",
    "print(df_combined.isna().sum().sort_values(ascending=False))\n",
    "\n",
    "#this outputs the null count rows count\n",
    "print(df_combined.isna().any(axis= 1).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>season</th>\n",
       "      <th>age</th>\n",
       "      <th>team</th>\n",
       "      <th>games</th>\n",
       "      <th>mp</th>\n",
       "      <th>pts</th>\n",
       "      <th>trb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>ts_pct</th>\n",
       "      <th>per</th>\n",
       "      <th>bpm</th>\n",
       "      <th>ws_per48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.J. Hammons</td>\n",
       "      <td>16-17</td>\n",
       "      <td>24.0</td>\n",
       "      <td>DAL</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.472</td>\n",
       "      <td>8.4</td>\n",
       "      <td>-6.6</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaron Brooks</td>\n",
       "      <td>16-17</td>\n",
       "      <td>32.0</td>\n",
       "      <td>IND</td>\n",
       "      <td>65.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.507</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron Gordon</td>\n",
       "      <td>16-17</td>\n",
       "      <td>21.0</td>\n",
       "      <td>ORL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>28.7</td>\n",
       "      <td>12.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.530</td>\n",
       "      <td>14.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaron Harrison</td>\n",
       "      <td>16-17</td>\n",
       "      <td>22.0</td>\n",
       "      <td>CHO</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-11.8</td>\n",
       "      <td>-0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adreian Payne</td>\n",
       "      <td>16-17</td>\n",
       "      <td>25.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.505</td>\n",
       "      <td>14.4</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Al Horford</td>\n",
       "      <td>16-17</td>\n",
       "      <td>30.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>68.0</td>\n",
       "      <td>32.3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.553</td>\n",
       "      <td>17.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Al Jefferson</td>\n",
       "      <td>16-17</td>\n",
       "      <td>32.0</td>\n",
       "      <td>IND</td>\n",
       "      <td>66.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.526</td>\n",
       "      <td>18.9</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>0.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Al-Farouq Aminu</td>\n",
       "      <td>16-17</td>\n",
       "      <td>26.0</td>\n",
       "      <td>POR</td>\n",
       "      <td>61.0</td>\n",
       "      <td>29.1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.506</td>\n",
       "      <td>11.3</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alan Anderson</td>\n",
       "      <td>16-17</td>\n",
       "      <td>34.0</td>\n",
       "      <td>LAC</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alan Williams</td>\n",
       "      <td>16-17</td>\n",
       "      <td>24.0</td>\n",
       "      <td>PHO</td>\n",
       "      <td>47.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.547</td>\n",
       "      <td>19.5</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alec Burks</td>\n",
       "      <td>16-17</td>\n",
       "      <td>25.0</td>\n",
       "      <td>UTA</td>\n",
       "      <td>42.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.501</td>\n",
       "      <td>11.6</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Alex Len</td>\n",
       "      <td>16-17</td>\n",
       "      <td>23.0</td>\n",
       "      <td>PHO</td>\n",
       "      <td>77.0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.553</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Alex Poythress</td>\n",
       "      <td>16-17</td>\n",
       "      <td>23.0</td>\n",
       "      <td>PHI</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>10.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.548</td>\n",
       "      <td>13.2</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>0.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Alexis Ajinça</td>\n",
       "      <td>16-17</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NOP</td>\n",
       "      <td>39.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>12.9</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Allen Crabbe</td>\n",
       "      <td>16-17</td>\n",
       "      <td>24.0</td>\n",
       "      <td>POR</td>\n",
       "      <td>79.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>10.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.602</td>\n",
       "      <td>11.6</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Alonzo Gee</td>\n",
       "      <td>16-17</td>\n",
       "      <td>29.0</td>\n",
       "      <td>DEN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.306</td>\n",
       "      <td>3.1</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>-0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Amir Johnson</td>\n",
       "      <td>16-17</td>\n",
       "      <td>29.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>80.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.628</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Anderson Varejão</td>\n",
       "      <td>16-17</td>\n",
       "      <td>34.0</td>\n",
       "      <td>GSW</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.478</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Andre Drummond</td>\n",
       "      <td>16-17</td>\n",
       "      <td>23.0</td>\n",
       "      <td>DET</td>\n",
       "      <td>81.0</td>\n",
       "      <td>29.7</td>\n",
       "      <td>13.6</td>\n",
       "      <td>13.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.518</td>\n",
       "      <td>20.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Andre Iguodala</td>\n",
       "      <td>16-17</td>\n",
       "      <td>33.0</td>\n",
       "      <td>GSW</td>\n",
       "      <td>76.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.624</td>\n",
       "      <td>14.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              player season   age team  games    mp   pts   trb  ast  stl  \\\n",
       "0       A.J. Hammons  16-17  24.0  DAL   22.0   7.4   2.2   1.6  0.2  0.0   \n",
       "1       Aaron Brooks  16-17  32.0  IND   65.0  13.8   5.0   1.1  1.9  0.4   \n",
       "2       Aaron Gordon  16-17  21.0  ORL   80.0  28.7  12.7   5.1  1.9  0.8   \n",
       "3     Aaron Harrison  16-17  22.0  CHO    5.0   3.4   0.2   0.6  0.6  0.0   \n",
       "4      Adreian Payne  16-17  25.0  MIN   18.0   7.5   3.5   1.8  0.4  0.4   \n",
       "5         Al Horford  16-17  30.0  BOS   68.0  32.3  14.0   6.8  5.0  0.8   \n",
       "6       Al Jefferson  16-17  32.0  IND   66.0  14.1   8.1   4.2  0.9  0.3   \n",
       "7    Al-Farouq Aminu  16-17  26.0  POR   61.0  29.1   8.7   7.4  1.6  1.0   \n",
       "8      Alan Anderson  16-17  34.0  LAC   30.0  10.3   2.9   0.8  0.4  0.1   \n",
       "9      Alan Williams  16-17  24.0  PHO   47.0  15.1   7.4   6.2  0.5  0.6   \n",
       "10        Alec Burks  16-17  25.0  UTA   42.0  15.5   6.7   2.9  0.7  0.4   \n",
       "11          Alex Len  16-17  23.0  PHO   77.0  20.3   8.0   6.6  0.6  0.5   \n",
       "12    Alex Poythress  16-17  23.0  PHI    6.0  26.2  10.7   4.8  0.8  0.5   \n",
       "13     Alexis Ajinça  16-17  28.0  NOP   39.0  15.0   5.3   4.5  0.3  0.5   \n",
       "14      Allen Crabbe  16-17  24.0  POR   79.0  28.5  10.7   2.9  1.2  0.7   \n",
       "15        Alonzo Gee  16-17  29.0  DEN   13.0   6.8   0.8   1.2  0.5  0.4   \n",
       "16      Amir Johnson  16-17  29.0  BOS   80.0  20.1   6.5   4.6  1.8  0.6   \n",
       "17  Anderson Varejão  16-17  34.0  GSW   14.0   6.6   1.3   1.9  0.7  0.2   \n",
       "18    Andre Drummond  16-17  23.0  DET   81.0  29.7  13.6  13.8  1.1  1.5   \n",
       "19    Andre Iguodala  16-17  33.0  GSW   76.0  26.3   7.6   4.0  3.4  1.0   \n",
       "\n",
       "    blk  ts_pct   per   bpm  ws_per48  \n",
       "0   0.6   0.472   8.4  -6.6    -0.001  \n",
       "1   0.1   0.507   9.5  -3.7     0.016  \n",
       "2   0.5   0.530  14.5  -1.0     0.077  \n",
       "3   0.0   0.102  -2.2 -11.8    -0.146  \n",
       "4   0.4   0.505  14.4  -2.3     0.086  \n",
       "5   1.3   0.553  17.7   3.4     0.138  \n",
       "6   0.2   0.526  18.9  -1.4     0.119  \n",
       "7   0.7   0.506  11.3  -1.1     0.051  \n",
       "8   0.0   0.494   5.0  -6.1     0.020  \n",
       "9   0.7   0.547  19.5  -1.3     0.142  \n",
       "10  0.1   0.501  11.6  -2.3     0.056  \n",
       "11  1.3   0.553  15.0  -2.3     0.091  \n",
       "12  0.3   0.548  13.2  -2.9     0.099  \n",
       "13  0.6   0.529  12.9  -3.3     0.080  \n",
       "14  0.3   0.602  11.6  -1.3     0.089  \n",
       "15  0.1   0.306   3.1  -6.7    -0.032  \n",
       "16  0.8   0.628  15.0   0.6     0.149  \n",
       "17  0.2   0.478   9.4  -4.2     0.097  \n",
       "18  1.1   0.518  20.9   1.0     0.133  \n",
       "19  0.5   0.624  14.3   2.5     0.167  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print some players \n",
    "df_combined.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the data. Note that we are dropping the duplicates for each season, and only taking the first entry because \n",
    "# duplicates only occur when players switch team. The first occurrence is always the average stats between that season.\n",
    "df_combined = df_combined.dropna()\n",
    "df_combined = df_combined.drop_duplicates(subset=[\"player\", \"season\"], keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "#teams and age were originally helping us to spot whether the dataset is correct, but we don't need it for future analysis.\n",
    "#so we also drop it.\n",
    "df_combined.dropna()\n",
    "df_combined = df_combined.drop(columns=[\"age\"])\n",
    "df_combined = df_combined.drop(columns=[\"team\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player      Aaron Harrison\n",
      "season               16-17\n",
      "games                  5.0\n",
      "mp                     3.4\n",
      "pts                    0.2\n",
      "trb                    0.6\n",
      "ast                    0.6\n",
      "stl                    0.0\n",
      "blk                    0.0\n",
      "ts_pct               0.102\n",
      "per                   -2.2\n",
      "bpm                  -11.8\n",
      "ws_per48            -0.146\n",
      "Name: 3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#This is one player who only played 5 games (out of a 82 game season). We believe this should be treated as an outlier because this significantly\n",
    "#increases the variance of the dataset.\n",
    "print(df_combined.iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#This drops players who played less or equal 41 games, because one season has 82 games and we believe that players who played too little games\n",
    "#will have a high variance in stats, weakening our analyis. (e.g. Aaron Harrison)\n",
    "df_combined = df_combined[df_combined[\"games\"] >41].reset_index(drop= True)\n",
    "\n",
    "df_combined = df_combined.drop(columns=[\"games\"])\n",
    "df_combined = df_combined.drop(columns=[\"mp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2424, 11)\n"
     ]
    }
   ],
   "source": [
    "#prints the shape of the data\n",
    "print(df_combined.shape)\n",
    "#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotrac NBA Contract and Salary Dataset (2016–17 to 2023–24)\n",
    "\n",
    "This dataset contains season-level NBA player compensation information compiled from Spotrac’s contract and payroll tables for the 2016–17 through 2023–24 seasons. In the raw extract, each row represents a player-team-season record, which produces about 5,000 rows because traded players can appear multiple times in the same year. For analysis, those split entries are collapsed into a single player-season `TOT` record, leaving roughly 4,100 unique player-season observations. The raw data includes 33 columns, with 10 primary variables retained for modeling compensation outcomes.\n",
    "\n",
    "The most important fields are `salary_usd` (guaranteed salary paid for that season, in U.S. dollars), `salary_cap` (the NBA salary cap for that season, in U.S. dollars), and `salary_share` (unitless proportion computed as `salary_usd / salary_cap`, which standardizes pay across cap environments). The dataset also includes `player` (name string), `season` (integer year code, where 2024 denotes the 2023–24 season), `team` (franchise identifier), `age` (integer), `contract_type` (categorical labels such as rookie-scale, veteran minimum, two-way, or max), `guaranteed` (guaranteed amount at signing, when available), and `notes` (text flags for incentives, options, or estimate tags). Together, these variables allow analysis of both absolute salary levels and relative cap burden, which is critical when comparing contracts across years with different league cap levels.\n",
    "\n",
    "There are several data-quality caveats to account for before inference. Mid-season trades create duplicate player-season rows unless explicitly collapsed to one `TOT` record. Some fringe contract types (for example, certain 10-day, Exhibit-10, or two-way arrangements) are not consistently captured, so the very bottom of the salary distribution may be underrepresented. In some cases, salary values include estimated incentives noted in `notes`, which introduces small measurement error (typically under 1%). Name formatting varies due to accents, suffixes, and middle initials, so normalization is necessary before merging with performance datasets like Basketball-Reference. Finally, `guaranteed` is often missing in single-season salary tabs and may need to be pulled from Spotrac’s full contract detail tables if guaranteed-at-signing analysis is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (9540, 9)\n",
      "\n",
      "Column names:\n",
      "['Player', 'Pos', 'Team                     Signed With', 'Age                     At Signing', 'Start', 'End', 'Yrs', 'Value', 'AAV']\n"
     ]
    }
   ],
   "source": [
    "# import and set up cell\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import unicodedata\n",
    "\n",
    "RAW_PATH = \"data/00-raw/NBA_Contracts.csv\"\n",
    "INTERIM_PATH = \"data/01-interim/\"\n",
    "PROCESSED_PATH = \"data/02-processed/\"\n",
    "\n",
    "os.makedirs(INTERIM_PATH, exist_ok=True)\n",
    "os.makedirs(PROCESSED_PATH, exist_ok=True)\n",
    "\n",
    "df_raw = pd.read_csv(RAW_PATH)\n",
    "print(f\"Shape: {df_raw.shape}\")\n",
    "print(f\"\\nColumn names:\\n{df_raw.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types\n",
      "Player                                   object\n",
      "Pos                                      object\n",
      "Team                     Signed With     object\n",
      "Age                     At Signing       object\n",
      "Start                                     int64\n",
      "End                                     float64\n",
      "Yrs                                     float64\n",
      "Value                                    object\n",
      "AAV                                      object\n",
      "dtype: object\n",
      "\n",
      "Null Counts\n",
      "Player                                    0\n",
      "Pos                                       0\n",
      "Team                     Signed With      0\n",
      "Age                     At Signing      275\n",
      "Start                                     0\n",
      "End                                       7\n",
      "Yrs                                      15\n",
      "Value                                   960\n",
      "AAV                                     961\n",
      "dtype: int64\n",
      "\n",
      "First 10 Rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Team                     Signed With</th>\n",
       "      <th>Age                     At Signing</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Yrs</th>\n",
       "      <th>Value</th>\n",
       "      <th>AAV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zyon Pullin</td>\n",
       "      <td>PG</td>\n",
       "      <td>MIA                  MIA</td>\n",
       "      <td>23</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zyon Pullin</td>\n",
       "      <td>PG</td>\n",
       "      <td>MEM                  MEM</td>\n",
       "      <td>23</td>\n",
       "      <td>2024</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zyon Pullin</td>\n",
       "      <td>PG</td>\n",
       "      <td>MIA                  MIA</td>\n",
       "      <td>23</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>$1,157,153</td>\n",
       "      <td>$1,157,153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zyon Pullin</td>\n",
       "      <td>PG</td>\n",
       "      <td>MIN                  MIN</td>\n",
       "      <td>24</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>$2,048,494</td>\n",
       "      <td>$2,048,494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zylan Cheatham</td>\n",
       "      <td>SF</td>\n",
       "      <td>NOP                  NOP</td>\n",
       "      <td>23</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Zylan Cheatham</td>\n",
       "      <td>SF</td>\n",
       "      <td>MIA                  MIA</td>\n",
       "      <td>26</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>$85,578</td>\n",
       "      <td>$8,558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zylan Cheatham</td>\n",
       "      <td>SF</td>\n",
       "      <td>NOP                  NOP</td>\n",
       "      <td>26</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>$89,057</td>\n",
       "      <td>$8,906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Zylan Cheatham</td>\n",
       "      <td>SF</td>\n",
       "      <td>UTA                  UTA</td>\n",
       "      <td>26</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>$89,057</td>\n",
       "      <td>$8,906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zylan Cheatham</td>\n",
       "      <td>SF</td>\n",
       "      <td>MIN                  MIN</td>\n",
       "      <td>25</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>$1,445,697</td>\n",
       "      <td>$1,445,697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zylan Cheatham</td>\n",
       "      <td>SF</td>\n",
       "      <td>NOP                  NOP</td>\n",
       "      <td>25</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>$1,489,065</td>\n",
       "      <td>$1,489,065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Player Pos Team                     Signed With  \\\n",
       "0     Zyon Pullin  PG             MIA                  MIA   \n",
       "1     Zyon Pullin  PG             MEM                  MEM   \n",
       "2     Zyon Pullin  PG             MIA                  MIA   \n",
       "3     Zyon Pullin  PG             MIN                  MIN   \n",
       "4  Zylan Cheatham  SF             NOP                  NOP   \n",
       "5  Zylan Cheatham  SF             MIA                  MIA   \n",
       "6  Zylan Cheatham  SF             NOP                  NOP   \n",
       "7  Zylan Cheatham  SF             UTA                  UTA   \n",
       "8  Zylan Cheatham  SF             MIN                  MIN   \n",
       "9  Zylan Cheatham  SF             NOP                  NOP   \n",
       "\n",
       "  Age                     At Signing  Start     End   Yrs       Value  \\\n",
       "0                                 23   2024  2024.0   1.0         NaN   \n",
       "1                                 23   2024  2025.0   2.0         NaN   \n",
       "2                                 23   2024  2024.0   1.0  $1,157,153   \n",
       "3                                 24   2025  2025.0   1.0  $2,048,494   \n",
       "4                                 23   2019  2019.0   1.0         NaN   \n",
       "5                                 26   2021  2021.0  10.0     $85,578   \n",
       "6                                 26   2021  2021.0  10.0     $89,057   \n",
       "7                                 26   2021  2021.0  10.0     $89,057   \n",
       "8                                 25   2020  2020.0   1.0  $1,445,697   \n",
       "9                                 25   2021  2021.0   1.0  $1,489,065   \n",
       "\n",
       "          AAV  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2  $1,157,153  \n",
       "3  $2,048,494  \n",
       "4         NaN  \n",
       "5      $8,558  \n",
       "6      $8,906  \n",
       "7      $8,906  \n",
       "8  $1,445,697  \n",
       "9  $1,489,065  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Data Types\")\n",
    "print(df_raw.dtypes)\n",
    "print(f\"\\nNull Counts\")\n",
    "print(df_raw.isnull().sum())\n",
    "print(f\"\\nFirst 10 Rows\")\n",
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after rename:\n",
      "['player', 'pos', 'team_signed_with', 'age_at_signing', 'start_year', 'end_year', 'yrs', 'value_str', 'aav_str']\n"
     ]
    }
   ],
   "source": [
    "# clean and verify column names\n",
    "\n",
    "df = df_raw.copy()\n",
    "\n",
    "df.columns = df.columns.str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "rename_map = {\n",
    "    \"Player\": \"player\",\n",
    "    \"Pos\": \"pos\",\n",
    "    \"Team Signed With\": \"team_signed_with\",\n",
    "    \"Age At Signing\": \"age_at_signing\",\n",
    "    \"Start\": \"start_year\",\n",
    "    \"End\": \"end_year\",\n",
    "    \"Yrs\": \"yrs\",\n",
    "    \"Value\": \"value_str\",\n",
    "    \"AAV\": \"aav_str\",\n",
    "}\n",
    "\n",
    "df = df.rename(columns=rename_map)\n",
    "print(\"Columns after rename:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique teams (34):\n",
      "['ATL', 'BKN', 'BOS', 'CHA', 'CHI', 'CLE', 'DAL', 'DEN', 'DET', 'GSW', 'HOU', 'IND', 'LAC', 'LAL', 'MEM', 'MIA', 'MIL', 'MIN', 'NJN', 'NOH', 'NOP', 'NYK', 'OKC', 'ORL', 'PHI', 'PHX', 'POR', 'SAC', 'SAS', 'SEA', 'TOR', 'UTA', 'VAN', 'WAS']\n"
     ]
    }
   ],
   "source": [
    "# clean and verify unique team names\n",
    "\n",
    "df[\"team\"] = df[\"team_signed_with\"].str.split(r'\\s+').str[0]\n",
    "\n",
    "print(f\"Unique teams ({df['team'].nunique()}):\")\n",
    "print(sorted(df[\"team\"].unique()))\n",
    "\n",
    "df = df.drop(columns=[\"team_signed_with\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed total_value\n",
      "count    8.580000e+03\n",
      "mean     1.050342e+07\n",
      "std      2.645607e+07\n",
      "min      1.000000e+00\n",
      "25%      6.292058e+05\n",
      "50%      1.637966e+06\n",
      "75%      6.509235e+06\n",
      "max      3.139334e+08\n",
      "Name: total_value, dtype: float64\n",
      "\n",
      "Parsed aav\n",
      "count    8.579000e+03\n",
      "mean     3.317885e+06\n",
      "std      6.454617e+06\n",
      "min      1.000000e+00\n",
      "25%      5.434710e+05\n",
      "50%      1.272870e+06\n",
      "75%      2.768904e+06\n",
      "max      6.832560e+07\n",
      "Name: aav, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# parse to numeric\n",
    "\n",
    "def parse_currency(series):\n",
    "    \"\"\"Remove $ and commas, convert to float. NaN stays NaN.\"\"\"\n",
    "    return (\n",
    "        series\n",
    "        .str.replace(\"$\", \"\", regex=False)\n",
    "        .str.replace(\",\", \"\", regex=False)\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "df[\"total_value\"] = parse_currency(df[\"value_str\"])\n",
    "df[\"aav\"] = parse_currency(df[\"aav_str\"])\n",
    "\n",
    "print(\"Parsed total_value\")\n",
    "print(df[\"total_value\"].describe())\n",
    "print(f\"\\nParsed aav\")\n",
    "print(df[\"aav\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓  original=$2,414,475  parsed=2414475.0  reconstructed=$2,414,475\n",
      "✓  original=$1,312,611  parsed=1312611.0  reconstructed=$1,312,611\n",
      "✓  original=$1,445,697  parsed=1445697.0  reconstructed=$1,445,697\n",
      "✓  original=$22,011,467  parsed=22011467.0  reconstructed=$22,011,467\n",
      "✓  original=$1,262,510  parsed=1262510.0  reconstructed=$1,262,510\n",
      "\n",
      "✓ Dropped string currency columns\n"
     ]
    }
   ],
   "source": [
    "# verification: reconstruct string from numeric and compare\n",
    "sample = df.dropna(subset=[\"value_str\"]).sample(5, random_state=42)\n",
    "for _, row in sample.iterrows():\n",
    "    original = row[\"value_str\"]\n",
    "    parsed = row[\"total_value\"]\n",
    "    reconstructed = f\"${parsed:,.0f}\"\n",
    "    match = \"✓\" if original == reconstructed else \"✗\"\n",
    "    print(f\"{match}  original={original}  parsed={parsed}  reconstructed={reconstructed}\")\n",
    "\n",
    "# drop string columns now that we have numeric\n",
    "df = df.drop(columns=[\"value_str\", \"aav_str\"])\n",
    "print(\"\\n✓ Dropped string currency columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age distribution\n",
      "count    9262.000000\n",
      "mean       24.898726\n",
      "std         4.061733\n",
      "min        12.000000\n",
      "25%        22.000000\n",
      "50%        24.000000\n",
      "75%        27.000000\n",
      "max        42.000000\n",
      "Name: age_at_signing, dtype: float64\n",
      "\n",
      "Null ages: 278\n",
      "\n",
      "⚠ 5 rows with age < 17 or > 45:\n",
      "                   player  age_at_signing  start_year  end_year team\n",
      "1460     Samuel Dalembert            15.0        2001    2004.0  PHI\n",
      "3038  Matthew Dellavedova            14.0        2015    2015.0  CLE\n",
      "3039  Matthew Dellavedova            12.0        2013    2014.0  CLE\n",
      "3042  Matthew Dellavedova            15.0        2016    2019.0  MIL\n",
      "5355        Jason Collins            13.0        2001    2004.0  NJN\n"
     ]
    }
   ],
   "source": [
    "# check age distribution and deal with unexpected values accordingly\n",
    "\n",
    "df[\"age_at_signing\"] = pd.to_numeric(df[\"age_at_signing\"], errors=\"coerce\")\n",
    "\n",
    "print(\"Age distribution\")\n",
    "print(df[\"age_at_signing\"].describe())\n",
    "print(f\"\\nNull ages: {df['age_at_signing'].isnull().sum()}\")\n",
    "\n",
    "suspicious_age = df[(df[\"age_at_signing\"] < 17) | (df[\"age_at_signing\"] > 45)]\n",
    "if len(suspicious_age) > 0:\n",
    "    print(f\"\\n⚠ {len(suspicious_age)} rows with age < 17 or > 45:\")\n",
    "    print(suspicious_age[[\"player\", \"age_at_signing\", \"start_year\", \"end_year\", \"team\"]].to_string())\n",
    "else:\n",
    "    print(\"\\n✓ All ages in plausible range (17–45)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting 5 rows with age < 17 to NaN\n",
      "                   player  age_at_signing  start_year\n",
      "1460     Samuel Dalembert            15.0        2001\n",
      "3038  Matthew Dellavedova            14.0        2015\n",
      "3039  Matthew Dellavedova            12.0        2013\n",
      "3042  Matthew Dellavedova            15.0        2016\n",
      "5355        Jason Collins            13.0        2001\n"
     ]
    }
   ],
   "source": [
    "AGE_FLOOR = 17\n",
    "\n",
    "implausible = df[\"age_at_signing\"] < AGE_FLOOR\n",
    "print(f\"Setting {implausible.sum()} rows with age < {AGE_FLOOR} to NaN\")\n",
    "print(df.loc[implausible, [\"player\", \"age_at_signing\", \"start_year\"]].to_string())\n",
    "\n",
    "df.loc[implausible, \"age_at_signing\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end_year range\n",
      "Min: 202.0, Max: 22016.0\n",
      "\n",
      "⚠ 4 rows with implausible end_year:\n",
      "               player  start_year  end_year   yrs\n",
      "1925        Raul Neto        2021     202.0   1.0\n",
      "2783       Mike Tobey        2016   22016.0  10.0\n",
      "3092  Marvin Williams        2019     219.0   1.0\n",
      "5210    Jaylen Morris        2018   12018.0   1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"end_year range\")\n",
    "print(f\"Min: {df['end_year'].min()}, Max: {df['end_year'].max()}\")\n",
    "\n",
    "# identify obvious typos (end_year > 2035 or < 1975)\n",
    "bad_end = df[(df[\"end_year\"] > 2035) | (df[\"end_year\"] < 1975)]\n",
    "print(f\"\\n⚠ {len(bad_end)} rows with implausible end_year:\")\n",
    "if len(bad_end) > 0:\n",
    "    print(bad_end[[\"player\", \"start_year\", \"end_year\", \"yrs\"]].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed 4 rows. Verification:\n",
      "               player  start_year  end_year   yrs\n",
      "1925        Raul Neto        2021    2021.0   1.0\n",
      "2783       Mike Tobey        2016    2025.0  10.0\n",
      "3092  Marvin Williams        2019    2019.0   1.0\n",
      "5210    Jaylen Morris        2018    2018.0   1.0\n",
      "\n",
      "end_year range now: 1980 – 2030\n"
     ]
    }
   ],
   "source": [
    "# noticed a typo pattern: extra digit prepended (22016 → 2016, 12018 → 2018)\n",
    "# fix by computing expected end from start + yrs - 1 where end_year is implausible\n",
    "\n",
    "mask_bad_end = (df[\"end_year\"] > 2035) | (df[\"end_year\"] < 1975)\n",
    "if mask_bad_end.sum() > 0:\n",
    "    df.loc[mask_bad_end, \"end_year\"] = df.loc[mask_bad_end, \"start_year\"] + df.loc[mask_bad_end, \"yrs\"] - 1\n",
    "    print(f\"Fixed {mask_bad_end.sum()} rows. Verification:\")\n",
    "    print(df.loc[mask_bad_end, [\"player\", \"start_year\", \"end_year\", \"yrs\"]].to_string())\n",
    "else:\n",
    "    print(\"✓ No end_year fixes needed\")\n",
    "\n",
    "df[\"end_year\"] = df[\"end_year\"].astype(\"Int64\")  \n",
    "df[\"yrs\"] = df[\"yrs\"].astype(\"Int64\")\n",
    "\n",
    "print(f\"\\nend_year range now: {df['end_year'].min()} – {df['end_year'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where end_year < start_year: 0\n",
      "\n",
      "Rows where yrs ≠ (end - start + 1): 1262\n",
      "                player  start_year  end_year  yrs  yrs_check\n",
      "5       Zylan Cheatham        2021      2021   10          1\n",
      "6       Zylan Cheatham        2021      2021   10          1\n",
      "7       Zylan Cheatham        2021      2021   10          1\n",
      "13  Zydrunas Ilgauskas        2010      2010    2          1\n",
      "23        Zhaire Smith        2023      2023   10          1\n",
      "28        Zhaire Smith        2018      2020    4          3\n",
      "39      Zavier Simpson        2021      2021   10          1\n",
      "40      Zavier Simpson        2023      2023   10          1\n",
      "41      Zavier Simpson        2023      2023   10          1\n",
      "55    Zach Norvell Jr.        2019      2019   10          1\n"
     ]
    }
   ],
   "source": [
    "# check: end_year should >= start_year\n",
    "backwards = df[df[\"end_year\"] < df[\"start_year\"]].dropna(subset=[\"end_year\"])\n",
    "print(f\"Rows where end_year < start_year: {len(backwards)}\")\n",
    "if len(backwards) > 0:\n",
    "    print(backwards[[\"player\", \"start_year\", \"end_year\", \"yrs\"]].head(10))\n",
    "\n",
    "# check: yrs should ≈ end_year - start_year + 1\n",
    "df[\"yrs_check\"] = df[\"end_year\"] - df[\"start_year\"] + 1\n",
    "mismatch = df[df[\"yrs\"] != df[\"yrs_check\"]].dropna(subset=[\"yrs\", \"yrs_check\"])\n",
    "print(f\"\\nRows where yrs ≠ (end - start + 1): {len(mismatch)}\")\n",
    "if len(mismatch) > 0:\n",
    "    print(mismatch[[\"player\", \"start_year\", \"end_year\", \"yrs\", \"yrs_check\"]].head(10))\n",
    "\n",
    "df = df.drop(columns=[\"yrs_check\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mismatched rows: 1262\n",
      "\n",
      "yrs value counts among mismatches\n",
      "yrs\n",
      "10    1034\n",
      "2       89\n",
      "4       41\n",
      "3       39\n",
      "1       19\n",
      "5       19\n",
      "6       14\n",
      "24       2\n",
      "12       2\n",
      "7        1\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Sample rows where yrs = 10 (likely 10-day contracts)\n",
      "              player  start_year  end_year  yrs  total_value      aav\n",
      "5     Zylan Cheatham        2021      2021   10      85578.0   8558.0\n",
      "6     Zylan Cheatham        2021      2021   10      89057.0   8906.0\n",
      "7     Zylan Cheatham        2021      2021   10      89057.0   8906.0\n",
      "23      Zhaire Smith        2023      2023   10     139290.0  13929.0\n",
      "39    Zavier Simpson        2021      2021   10      37223.0   3722.0\n",
      "40    Zavier Simpson        2023      2023   10      62130.0   6213.0\n",
      "41    Zavier Simpson        2023      2023   10     103550.0  10355.0\n",
      "55  Zach Norvell Jr.        2019      2019   10      50752.0   5075.0\n",
      "81      Yuri Collins        2024      2024   10      66503.0   6650.0\n",
      "93      Yogi Ferrell        2016      2016   10      31969.0   3197.0\n",
      "\n",
      "Sample rows where yrs != 10 (multi-year contracts)\n",
      "                 player  start_year  end_year  yrs  total_value        aav\n",
      "13   Zydrunas Ilgauskas        2010      2010    2    2751688.0  1375844.0\n",
      "28         Zhaire Smith        2018      2020    4   13791056.0  3447764.0\n",
      "96         Yogi Ferrell        2016      2017    1     207798.0   207798.0\n",
      "168         Willie Reed        2013      2014    1     102089.0   102089.0\n",
      "266     Wayne Ellington        2019      2019    2   16000000.0  8000000.0\n",
      "289           Von Wafer        2011      2013    1     992680.0   992680.0\n",
      "318       Vince Edwards        2018      2019    1          NaN        NaN\n",
      "367       Udonis Haslem        2010      2013    5   20300000.0  4060000.0\n",
      "457       Tyler Johnson        2014      2014    2    1352385.0   676193.0\n",
      "460     Tyler Honeycutt        2011      2012    3    2469168.0   823056.0\n"
     ]
    }
   ],
   "source": [
    "# investigate the yrs mismatch pattern\n",
    "\n",
    "mismatched = df_deduped if \"df_deduped\" in dir() else df_filtered if \"df_filtered\" in dir() else df\n",
    "\n",
    "yrs_check = mismatched[\"end_year\"] - mismatched[\"start_year\"] + 1\n",
    "mismatch_mask = (mismatched[\"yrs\"] != yrs_check) & mismatched[\"yrs\"].notna() & mismatched[\"end_year\"].notna()\n",
    "\n",
    "mismatch_df = mismatched[mismatch_mask].copy()\n",
    "mismatch_df[\"yrs_check\"] = yrs_check[mismatch_mask]\n",
    "\n",
    "print(f\"Total mismatched rows: {len(mismatch_df)}\")\n",
    "print(f\"\\nyrs value counts among mismatches\")\n",
    "print(mismatch_df[\"yrs\"].value_counts().head(10))\n",
    "\n",
    "print(f\"\\nSample rows where yrs = 10 (likely 10-day contracts)\")\n",
    "print(mismatch_df[mismatch_df[\"yrs\"] == 10][[\"player\", \"start_year\", \"end_year\", \"yrs\", \"total_value\", \"aav\"]].head(10))\n",
    "\n",
    "print(f\"\\nSample rows where yrs != 10 (multi-year contracts)\")\n",
    "print(mismatch_df[mismatch_df[\"yrs\"] != 10][[\"player\", \"start_year\", \"end_year\", \"yrs\", \"total_value\", \"aav\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-day contract rows: 1034\n",
      "Regular contract rows: 8497\n",
      "\n",
      "0-day contract AAV summary\n",
      "count     1030.000000\n",
      "mean      7777.564078\n",
      "std       3822.508010\n",
      "min        585.000000\n",
      "25%       4856.000000\n",
      "50%       6890.000000\n",
      "75%       9938.000000\n",
      "max      22785.000000\n",
      "Name: aav, dtype: float64\n",
      "\n",
      "Regular contract AAV summary\n",
      "count    7.549000e+03\n",
      "mean     3.769522e+06\n",
      "std      6.756339e+06\n",
      "min      1.000000e+00\n",
      "25%      8.450590e+05\n",
      "50%      1.476688e+06\n",
      "75%      3.203542e+06\n",
      "max      6.832560e+07\n",
      "Name: aav, dtype: float64\n",
      "\n",
      "✓ Note: 'yrs' = total contract length at signing, not row-level season span\n",
      "  For 10-day contracts, yrs=10 means 10 DAYS, not 10 years\n"
     ]
    }
   ],
   "source": [
    "# flag 10-day contracts based on: yrs == 10 AND start_year == end_year AND low value\n",
    "df[\"is_10day\"] = (\n",
    "    (df[\"yrs\"] == 10) & \n",
    "    (df[\"start_year\"] == df[\"end_year\"].astype(\"float\"))\n",
    ")\n",
    "\n",
    "print(f\"10-day contract rows: {df['is_10day'].sum()}\")\n",
    "print(f\"Regular contract rows: {(~df['is_10day']).sum()}\")\n",
    "\n",
    "print(f\"\\n0-day contract AAV summary\")\n",
    "print(df.loc[df[\"is_10day\"], \"aav\"].describe())\n",
    "\n",
    "print(f\"\\nRegular contract AAV summary\")\n",
    "print(df.loc[~df[\"is_10day\"], \"aav\"].describe())\n",
    "\n",
    "print(\"\\n✓ Note: 'yrs' = total contract length at signing, not row-level season span\")\n",
    "print(\"  For 10-day contracts, yrs=10 means 10 DAYS, not 10 years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position value counts\n",
      "pos\n",
      "SG     2036\n",
      "PG     1905\n",
      "PF     1775\n",
      "SF     1699\n",
      "C      1442\n",
      "G       428\n",
      "F       254\n",
      "COA       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# investigate position values\n",
    "\n",
    "print(\"Position value counts\")\n",
    "print(df[\"pos\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 1 non-player rows:\n",
      "                player  pos team  start_year\n",
      "6057  Hunter Dickinson  COA  NOP        2025\n",
      "\n",
      "Shape after filtering: (9539, 10)\n"
     ]
    }
   ],
   "source": [
    "# \"COA\" appears to be coaching staff — not a player contract\n",
    "\n",
    "non_player_pos = [\"COA\"]\n",
    "\n",
    "mask = df[\"pos\"].isin(non_player_pos)\n",
    "if mask.sum() > 0:\n",
    "    print(f\"Removing {mask.sum()} non-player rows:\")\n",
    "    print(df.loc[mask, [\"player\", \"pos\", \"team\", \"start_year\"]].to_string())\n",
    "    df = df[~mask].reset_index(drop=True)\n",
    "else:\n",
    "    print(\"✓ No non-player rows found\")\n",
    "\n",
    "print(f\"\\nShape after filtering: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_year distribution\n",
      "start_year\n",
      "1976      1\n",
      "1979      2\n",
      "1981      1\n",
      "1984      5\n",
      "1985      4\n",
      "1986      2\n",
      "1987      4\n",
      "1988      4\n",
      "1989      5\n",
      "1990      8\n",
      "1991      9\n",
      "1992      5\n",
      "1993     13\n",
      "1994     13\n",
      "1995     17\n",
      "1996     26\n",
      "1997     18\n",
      "1998     30\n",
      "1999     40\n",
      "2000     35\n",
      "2001     40\n",
      "2002     36\n",
      "2003     74\n",
      "2004     64\n",
      "2005    107\n",
      "2006     76\n",
      "2007    104\n",
      "2008    127\n",
      "2009    153\n",
      "2010    236\n",
      "2011    300\n",
      "2012    423\n",
      "2013    445\n",
      "2014    451\n",
      "2015    458\n",
      "2016    474\n",
      "2017    506\n",
      "2018    510\n",
      "2019    555\n",
      "2020    488\n",
      "2021    764\n",
      "2022    579\n",
      "2023    801\n",
      "2024    777\n",
      "2025    720\n",
      "2026     24\n",
      "2027      4\n",
      "2028      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "end_year distribution\n",
      "end_year\n",
      "1980      1\n",
      "1983      2\n",
      "1985      1\n",
      "1987      4\n",
      "1988      6\n",
      "1989      4\n",
      "1990      3\n",
      "1991      5\n",
      "1992      6\n",
      "1993      7\n",
      "1994      4\n",
      "1995     13\n",
      "1996     10\n",
      "1997     29\n",
      "1998     22\n",
      "1999     24\n",
      "2000     19\n",
      "2001     16\n",
      "2002     45\n",
      "2003     39\n",
      "2004     63\n",
      "2005     53\n",
      "2006     76\n",
      "2007     84\n",
      "2008     95\n",
      "2009    147\n",
      "2010    198\n",
      "2011    329\n",
      "2012    346\n",
      "2013    432\n",
      "2014    463\n",
      "2015    440\n",
      "2016    432\n",
      "2017    517\n",
      "2018    551\n",
      "2019    553\n",
      "2020    506\n",
      "2021    723\n",
      "2022    586\n",
      "2023    779\n",
      "2024    755\n",
      "2025    750\n",
      "2026    180\n",
      "2027    108\n",
      "2028     78\n",
      "2029     21\n",
      "2030      7\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "# investigate start year and end year distributions\n",
    "\n",
    "print(\"start_year distribution\")\n",
    "print(df[\"start_year\"].value_counts().sort_index())\n",
    "print(f\"\\nend_year distribution\")\n",
    "print(df[\"end_year\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after season filter: 5366\n",
      "Start year range: 2013 – 2024\n",
      "End year range:   2017 – 2028\n",
      "Unique players:   1795\n"
     ]
    }
   ],
   "source": [
    "# apply filter to keep contracts that were active any point during our target window (2017-24)\n",
    "\n",
    "df_filtered = df[(df[\"start_year\"] <= 2024) & (df[\"end_year\"] >= 2017)].copy()\n",
    "df_filtered = df_filtered.reset_index(drop=True)\n",
    "\n",
    "print(f\"Rows after season filter: {len(df_filtered)}\")\n",
    "print(f\"Start year range: {df_filtered['start_year'].min()} – {df_filtered['start_year'].max()}\")\n",
    "print(f\"End year range:   {df_filtered['end_year'].min()} – {df_filtered['end_year'].max()}\")\n",
    "print(f\"Unique players:   {df_filtered['player'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Players with accented characters: 11\n",
      "['Jae’Sean Tate' 'Élie Okobo' 'D’Moi Hodge' 'Dennis Schröder']\n",
      "\n",
      "Players with suffixes: 29\n",
      "['Trey Murphy III' 'Tolu Smith III' 'Ron Holland II' 'Robert Woodard II'\n",
      " 'Robert Williams III' 'Ricky Council IV' 'Perry Jones III'\n",
      " 'McKinley Wright IV' 'Matt Coleman III' 'Marvin Bagley III'\n",
      " 'Lonnie Walker IV' 'Lindy Waters III' 'Larry Drew II' 'Landers Nolley II'\n",
      " 'Kelvin Jones II']\n",
      "\n",
      "Players with extra whitespace: 0\n",
      "Players with leading/trailing whitespace: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2540/1180255600.py:10: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  suffixes = df_filtered[\"player\"][df_filtered[\"player\"].str.contains(r'\\b(Jr\\.|Sr\\.|III|II|IV)\\b', regex=True)]\n"
     ]
    }
   ],
   "source": [
    "# check for accent characters\n",
    "has_accents = df_filtered[\"player\"].apply(\n",
    "    lambda x: x != unicodedata.normalize(\"NFKD\", x).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    ")\n",
    "print(f\"Players with accented characters: {has_accents.sum()}\")\n",
    "if has_accents.sum() > 0:\n",
    "    print(df_filtered.loc[has_accents, \"player\"].unique()[:20])\n",
    "\n",
    "# check for suffixes\n",
    "suffixes = df_filtered[\"player\"][df_filtered[\"player\"].str.contains(r'\\b(Jr\\.|Sr\\.|III|II|IV)\\b', regex=True)]\n",
    "print(f\"\\nPlayers with suffixes: {suffixes.nunique()}\")\n",
    "print(suffixes.unique()[:15])\n",
    "\n",
    "# check for extra whitespace\n",
    "has_extra_ws = df_filtered[\"player\"].str.contains(r'  +')\n",
    "print(f\"\\nPlayers with extra whitespace: {has_extra_ws.sum()}\")\n",
    "\n",
    "# check for leading/trailing whitespace\n",
    "has_edge_ws = df_filtered[\"player\"].str.strip() != df_filtered[\"player\"]\n",
    "print(f\"Players with leading/trailing whitespace: {has_edge_ws.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique players after normalization: 1795\n",
      "Player names normalized (whitespace cleaned)\n"
     ]
    }
   ],
   "source": [
    "# strip whitespace and collapse internal whitespace\n",
    "df_filtered[\"player\"] = (\n",
    "    df_filtered[\"player\"]\n",
    "    .str.strip()\n",
    "    .str.replace(r'\\s+', ' ', regex=True)\n",
    ")\n",
    "\n",
    "print(f\"Unique players after normalization: {df_filtered['player'].nunique()}\")\n",
    "print(\"Player names normalized (whitespace cleaned)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact duplicate rows: 264\n",
      "                  player pos  age_at_signing  start_year  end_year  yrs team  \\\n",
      "5291         A.J. Lawson   F            22.0        2022      2022    1  MIN   \n",
      "5290         A.J. Lawson   F            22.0        2022      2022    1  MIN   \n",
      "5322   Admiral Schofield  SF            24.0        2021      2021   10  ORL   \n",
      "5321   Admiral Schofield  SF            24.0        2021      2021   10  ORL   \n",
      "5237          Alex Reese   F            25.0        2024      2024    1  OKC   \n",
      "5238          Alex Reese   F            25.0        2024      2024    1  OKC   \n",
      "5222    Alfonzo McKinnie  SF            26.0        2019      2019   10  CLE   \n",
      "5223    Alfonzo McKinnie  SF            26.0        2019      2019   10  CLE   \n",
      "5076  Antonius Cleveland  SG            22.0        2017      2017   10  ATL   \n",
      "5075  Antonius Cleveland  SG            22.0        2017      2017   10  ATL   \n",
      "\n",
      "      total_value        aav  is_10day  \n",
      "5291          NaN        NaN     False  \n",
      "5290          NaN        NaN     False  \n",
      "5322      85578.0     8558.0      True  \n",
      "5321      85578.0     8558.0      True  \n",
      "5237    1157153.0  1157153.0     False  \n",
      "5238    1157153.0  1157153.0     False  \n",
      "5222      91557.0     9156.0      True  \n",
      "5223      91557.0     9156.0      True  \n",
      "5076      46080.0     4608.0      True  \n",
      "5075      46080.0     4608.0      True  \n"
     ]
    }
   ],
   "source": [
    "# checking for duplicate rows (different contracts for same player-season, keeping highest AAV per player-season)\n",
    "\n",
    "exact_dupes = df_filtered.duplicated(keep=False)\n",
    "print(f\"Exact duplicate rows: {exact_dupes.sum()}\")\n",
    "if exact_dupes.sum() > 0:\n",
    "    print(df_filtered[exact_dupes].sort_values(\"player\").head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before dedup: 5366\n",
      "Rows after dedup:  4045\n",
      "Rows removed: 1321\n"
     ]
    }
   ],
   "source": [
    "pre_dedup = len(df_filtered)\n",
    "\n",
    "df_deduped = (\n",
    "    df_filtered\n",
    "    .sort_values(\"aav\", ascending=False, na_position=\"last\")\n",
    "    .drop_duplicates(subset=[\"player\", \"start_year\"], keep=\"first\")\n",
    "    .sort_values([\"player\", \"start_year\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"Rows before dedup: {pre_dedup}\")\n",
    "print(f\"Rows after dedup:  {len(df_deduped)}\")\n",
    "print(f\"Rows removed: {pre_dedup - len(df_deduped)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ No player-season duplicates remain\n",
      "✓ Final shape: (4045, 10)\n"
     ]
    }
   ],
   "source": [
    "# no player should appear more than once per start_year\n",
    "remaining_dupes = df_deduped.duplicated(subset=[\"player\", \"start_year\"], keep=False)\n",
    "assert remaining_dupes.sum() == 0, f\"Still have {remaining_dupes.sum()} duplicates!\"\n",
    "print(f\"✓ No player-season duplicates remain\")\n",
    "print(f\"✓ Final shape: {df_deduped.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL DATA QUALITY REPORT\n",
      "\n",
      "Shape: (4045, 10)\n",
      "Unique players: 1795\n",
      "Season range: 2013 – 2024\n",
      "\n",
      "--- Null Counts ---\n",
      "player              0\n",
      "pos                 0\n",
      "age_at_signing     39\n",
      "start_year          0\n",
      "end_year            0\n",
      "yrs                 4\n",
      "team                0\n",
      "total_value       337\n",
      "aav               337\n",
      "is_10day            4\n",
      "dtype: int64\n",
      "\n",
      "--- Numeric Summary ---\n",
      "       age_at_signing   start_year     end_year       yrs   total_value  \\\n",
      "count     4006.000000  4045.000000       4045.0    4041.0  3.708000e+03   \n",
      "mean        24.844483  2020.276391  2021.167862  2.103192  1.382572e+07   \n",
      "std          4.100854     2.710523     2.666652  1.709465  3.109090e+07   \n",
      "min         18.000000  2013.000000       2017.0       1.0  5.849000e+03   \n",
      "25%         22.000000  2018.000000       2019.0       1.0  1.119563e+06   \n",
      "50%         24.000000  2021.000000       2021.0       1.0  2.321832e+06   \n",
      "75%         27.000000  2023.000000       2023.0       3.0  1.015124e+07   \n",
      "max         42.000000  2024.000000       2028.0      12.0  2.853936e+08   \n",
      "\n",
      "                aav  \n",
      "count  3.708000e+03  \n",
      "mean   4.464120e+06  \n",
      "std    7.421256e+06  \n",
      "min    5.850000e+02  \n",
      "25%    1.017781e+06  \n",
      "50%    1.801769e+06  \n",
      "75%    3.596208e+06  \n",
      "max    5.707873e+07  \n",
      "\n",
      "--- Categorical Summary ---\n",
      "\n",
      "pos: 7 unique\n",
      "pos\n",
      "SG    927\n",
      "PG    787\n",
      "SF    705\n",
      "PF    650\n",
      "C     599\n",
      "G     250\n",
      "F     127\n",
      "Name: count, dtype: int64\n",
      "\n",
      "team: 30 unique\n",
      "team\n",
      "MIL    166\n",
      "LAL    163\n",
      "NYK    160\n",
      "PHI    155\n",
      "HOU    152\n",
      "BOS    148\n",
      "NOP    147\n",
      "SAC    141\n",
      "OKC    141\n",
      "BKN    141\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"FINAL DATA QUALITY REPORT\")\n",
    "\n",
    "print(f\"\\nShape: {df_deduped.shape}\")\n",
    "print(f\"Unique players: {df_deduped['player'].nunique()}\")\n",
    "print(f\"Season range: {df_deduped['start_year'].min()} – {df_deduped['start_year'].max()}\")\n",
    "\n",
    "print(f\"\\n--- Null Counts ---\")\n",
    "print(df_deduped.isnull().sum())\n",
    "\n",
    "print(f\"\\n--- Numeric Summary ---\")\n",
    "print(df_deduped.describe())\n",
    "\n",
    "print(f\"\\n--- Categorical Summary ---\")\n",
    "for col in [\"pos\", \"team\"]:\n",
    "    print(f\"\\n{col}: {df_deduped[col].nunique()} unique\")\n",
    "    print(df_deduped[col].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ No null players\n",
      "  ✓ No null teams\n",
      "  ✓ No null start_year\n",
      "  ✓ Valid positions only\n",
      "  ✓ start_year <= 2024\n",
      "  ✓ end_year >= 2017\n",
      "  ✓ No negative values\n",
      "  ✓ No player-season dupes\n",
      "  ✓ No implausible ages\n",
      "\n",
      "✓ ALL CHECKS PASSED\n"
     ]
    }
   ],
   "source": [
    "checks = {\n",
    "    \"No null players\": df_deduped[\"player\"].isnull().sum() == 0,\n",
    "    \"No null teams\": df_deduped[\"team\"].isnull().sum() == 0,\n",
    "    \"No null start_year\": df_deduped[\"start_year\"].isnull().sum() == 0,\n",
    "    \"Valid positions only\": df_deduped[\"pos\"].isin([\"PG\",\"SG\",\"SF\",\"PF\",\"C\",\"G\",\"F\"]).all(),\n",
    "    \"start_year <= 2024\": (df_deduped[\"start_year\"] <= 2024).all(),\n",
    "    \"end_year >= 2017\": (df_deduped[\"end_year\"] >= 2017).all(),\n",
    "    \"No negative values\": (df_deduped[\"total_value\"].dropna() >= 0).all(),\n",
    "    \"No player-season dupes\": df_deduped.duplicated(subset=[\"player\",\"start_year\"]).sum() == 0,\n",
    "    \"No implausible ages\": (df_deduped[\"age_at_signing\"].dropna() >= 17).all(),\n",
    "}\n",
    "\n",
    "for name, passed in checks.items():\n",
    "    status = \"✓\" if passed else \"✗\"\n",
    "    print(f\"  {status} {name}\")\n",
    "\n",
    "if all(checks.values()):\n",
    "    print(\"\\n✓ ALL CHECKS PASSED\")\n",
    "else:\n",
    "    print(\"\\n⚠ SOME CHECKS FAILED — review before proceeding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved processed file to: data/02-processed/nba_contracts_processed.csv\n",
      "  Shape: (4045, 9)\n",
      "  Columns: ['player', 'pos', 'team', 'age_at_signing', 'start_year', 'end_year', 'yrs', 'total_value', 'aav']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>pos</th>\n",
       "      <th>team</th>\n",
       "      <th>age_at_signing</th>\n",
       "      <th>start_year</th>\n",
       "      <th>end_year</th>\n",
       "      <th>yrs</th>\n",
       "      <th>total_value</th>\n",
       "      <th>aav</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.J. Griffin</td>\n",
       "      <td>SF</td>\n",
       "      <td>ATL</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>2025</td>\n",
       "      <td>4</td>\n",
       "      <td>17106137.0</td>\n",
       "      <td>4276534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A.J. Hammons</td>\n",
       "      <td>C</td>\n",
       "      <td>DAL</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>2605511.0</td>\n",
       "      <td>868504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A.J. Lawson</td>\n",
       "      <td>F</td>\n",
       "      <td>ATL</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>925258.0</td>\n",
       "      <td>925258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A.J. Lawson</td>\n",
       "      <td>F</td>\n",
       "      <td>DAL</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A.J. Lawson</td>\n",
       "      <td>F</td>\n",
       "      <td>DAL</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>2026</td>\n",
       "      <td>4</td>\n",
       "      <td>7912022.0</td>\n",
       "      <td>1978006.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         player pos team  age_at_signing  start_year  end_year  yrs  \\\n",
       "0  A.J. Griffin  SF  ATL            18.0        2022      2025    4   \n",
       "1  A.J. Hammons   C  DAL            23.0        2016      2018    3   \n",
       "2   A.J. Lawson   F  ATL            21.0        2021      2021    1   \n",
       "3   A.J. Lawson   F  DAL            22.0        2022      2023    2   \n",
       "4   A.J. Lawson   F  DAL            23.0        2023      2026    4   \n",
       "\n",
       "   total_value        aav  \n",
       "0   17106137.0  4276534.0  \n",
       "1    2605511.0   868504.0  \n",
       "2     925258.0   925258.0  \n",
       "3          NaN        NaN  \n",
       "4    7912022.0  1978006.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save final processed data\n",
    "\n",
    "final_cols = [\n",
    "    \"player\", \"pos\", \"team\", \"age_at_signing\",\n",
    "    \"start_year\", \"end_year\", \"yrs\",\n",
    "    \"total_value\", \"aav\"\n",
    "]\n",
    "\n",
    "df_final = df_deduped[final_cols].copy()\n",
    "\n",
    "processed_file = os.path.join(PROCESSED_PATH, \"nba_contracts_processed.csv\")\n",
    "df_final.to_csv(processed_file, index=False)\n",
    "print(f\"✓ Saved processed file to: {processed_file}\")\n",
    "print(f\"  Shape: {df_final.shape}\")\n",
    "print(f\"  Columns: {df_final.columns.tolist()}\")\n",
    "df_final.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics\n",
    "\n",
    "Here is a [list of real world examples](https://deon.drivendata.org/examples/) for each item in the checklist that can refer to.\n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "\n",
    "    Although NBA salaries and performance statistics are in the public domain, our research involves the financial data of identifiable individuals. The principle of Beneficence dictates that our study should focus on aggregate market trends and systemic patterns rather than singling out specific athletes as \"outliers\" or \"overpaid.\" The data should be handled by us with professional decorum, ensuring our research serves to advance the understanding of sports economics and labor market efficiency without causing undue reputational harm to the individuals being studied.\n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    " - [X] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "\n",
    "    When analyzing the degree to which box-score and advanced metrics explain salary cap share, we have an ethical obligation to maintain \"epistemological integrity.\" This means clearly distinguishing between statistical explanation (correlation) and causation. Us researchers must avoid \"p-hacking\" or manipulating the data range (2016–2024) to find a higher $R^2$ value. Ethically, our findings must be presented transparently, even if the chosen metrics fail to explain a significant portion of the salary variance, to avoid creating a false narrative about how the NBA labor market operates.\n",
    "\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    " - [X] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    "\n",
    "    The selection of independent variables, specifically \"all-in\" metrics like PER, BPM, and Win Shares, carries an ethical weight. These metrics are human-made constructs with inherent biases (e.g., PER’s favoritism toward high-volume shooting). In our research, it is ethically necessary to acknowledge that using these metrics is an audit of the metrics themselves as much as it is an audit of the NBA’s salary structure. Us researchers must ensure the limitations of these mathematical formulas are disclosed so that the \"explanation\" provided is not mistaken for an objective truth about a player's total worth.\n",
    "\n",
    " - [X] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "    Ethical research requires a high degree of transparency regarding what the data cannot see. By focusing strictly on box scores and selected advanced stats, our study inherently ignores qualitative factors such as leadership, injury history, and defensive \"gravity.\" It is an ethical imperative to frame the results with the caveat that these metrics only capture a portion of a player's professional value. This prevents the research from being misinterpreted as a definitive guide for what a player \"should\" be paid, which could otherwise be used to unfairly minimize the value of unquantifiable contributions.\n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    "\n",
    "    Plan: We will implement a seasonal monitoring cycle to account for model drift. Because salary cap rules, positional value, and market behaviors shift annually, the model will be re-run each season. We will compare year-over-year performance, audit sample predictions, and generate a stability report to ensure the model remains accurate under new season conditions.\n",
    " - [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    "\n",
    "    Plan: We have established a response protocol for cases where a player may be reputationally harmed by model results (e.g., being publicly labeled as \"overpaid\"). We will evaluate these cases by auditing the specific inputs and logic that led to the label and will provide a mechanism to update the analysis if the harm stems from data inaccuracies or biased features.\n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    "\n",
    "    Plan: We have a \"kill switch\" and version control system in place. If errors are discovered in our analysis or visualizations after deployment, we can immediately roll back to a previous stable version or take the dashboard offline to prevent the spread of incorrect insights while we fix the underlying issue.\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "\n",
    "    Plan: To prevent misuse, all model outputs will include clear documentation and disclaimers. Specifically, we will explicitly state that the model identifies correlations, not causal relationships, to prevent stakeholders from assuming that changing one specific metric will certainly result in a higher salary. We will also monitor for \"shadow\" uses where the model might be used outside its intended scope (e.g., for injury prediction).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Communication\n",
    "- Primary channel: Discord (text + voice). Communicate via email if discord is not working.\n",
    "- Response window: ≤ 24 hrs Mon-Fri, ≤ 36 hrs on weekends.\n",
    "- Tone: “blunt-but-polite”. \n",
    "- Guidelines: Use I-statements, assume good intent, and ask clarifying questions. Whenever a conflict arises, focus on addressing the issue and not blaming other groupmates.\n",
    "\n",
    "### Meetings\n",
    "- Baseline: meet once per week. We can be flexible about meeting time as long as we meet the baseline. \n",
    "- More meetings shall be scheduled if necessary, and especially if closer to a deadline.\n",
    "- Meetings should preferably be in person. Online meetings shall be made if it happens late at night (e.g. after 9PM), or if an unexpected circumstance happens to prevent arrival on the designated location on time.\n",
    "\n",
    "### Decision-Making\n",
    "- Decisions should be made in consensus. \n",
    "- If no consensus after 10 min, decide by simple majority vote. If someone is unable to show up for a particular decision and does not offer one virtually, their vote is automatically rescinded.\n",
    "- When a deadline is < 24 hrs away, a decision can be made with the minimum of confirmation of 3 members. When a deadline is < 10 hrs away, a decision can be made with the minimum of confirmation of 2 members. When a deadline is < 2 hrs away, a decision can be made unilaterally given that 1) The decision-maker is fully confident that the decision will be more beneficial to the group than harmful; 2) The decision-maker will take full responsibility for the decision after it is made; 3) If other group members do not respond in a 30 minute window. \n",
    "- Regarding the previous point, no group member is allowed to make more than one unilateral decision. It should be treated as an absolute last-resort decision.\n",
    "\n",
    "### Deadlines\n",
    "- Internal deadlines are 48 hrs before the actual assignment deadline.\n",
    "- Members should agree on the final deliverable before the deadline. Otherwise, extra meeting(s) should be called as soon as possible to discuss refinements.\n",
    "\n",
    "### Conflict-Resolution Process\n",
    "- Calm yourself down. A decision shall only be made when every group member is not impacted by their emotions.\n",
    "- Think before you talk! Don’t talk just because you want to win the argument.\n",
    "- Step into the other party’s shoes. There are often overlaps even when there seems to be complete disagreements.\n",
    "- If absolutely necessary, talk to TAs about this issue and fix the problem together (last resort).\n",
    "- If a group member does work late/does not meet team expectations, directly speak with the relevant group member and help them out but reinforce team expectations. If this happens recurrently, reach out to TAs.\n",
    "\n",
    "### Inclusivity & Well-Being\n",
    "- In an online meeting: Cameras optional; mic required.\n",
    "- Allow religious holidays and accessibility needs.\n",
    "- No “stacking” late-night deadlines.\n",
    "\n",
    "### Agreement\n",
    "By signing below with their full name, each group member confirms they have read, understand, and agree to follow the team expectations.\n",
    "\n",
    "- Jimmy Ouyang\n",
    "- Jeremy Wei\n",
    "- Zack Chen\n",
    "- Subika Haider\n",
    "- Jerry Ying\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Meeting Schedule\n",
    "\n",
    "| Meeting Date | Meeting Time | Completed Before Meeting | Discuss at Meeting | Status |\n",
    "|-------------|--------------|--------------------------|-------------------|--------|\n",
    "| 1/26/2026 | 17:00 | Determine the best form of communication; read & think about COGS 108 project expectations; review previous COGS 108 projects | Assign group-member tasks; review and discuss selected COGS 108 projects; analyze and evaluate the projects | ✅ |\n",
    "| 2/3/2026  | 21:30 | Read through COGS108 project-proposal documents and critically analyze them | Discuss ideal dataset(s) and ethics; draft project proposal; assign group-member tasks | ✅ |\n",
    "| 2/4/2026  | 13:00 | Members complete assigned tasks; finish first draft of project proposal | Discuss and complete final project proposal | ✅ |\n",
    "| 2/8/2026  | 21:00 | N/A | Discuss and confirm tasks assigned to each member until next progress check | ✅ |\n",
    "| 2/11/2026 | 13:30 | Group members make progress on assigned tasks | Progress check and peer review | ✅ |\n",
    "| 2/17/2026 | 21:00 | Group members complete Checkpoint 1 requirements | Discuss and finalize Checkpoint 1 document; confirm tasks until next progress check | ✅ |\n",
    "| 2/18/2026 | 13:00 | Group members finalize Checkpoint 1 requirements | Discuss and finalize Checkpoint 1 document; confirm tasks until next progress check | ⏳ |\n",
    "| 2/25/2026 | 13:00 | Progress on data import,wrangling, and EDA | Progress check and peer review; review/edit wrangling & EDA; discuss analysis plan | ⏳ |\n",
    "| 3/3/2026  | 13:00 | Finalize wrangling, EDA, and analysis | Discuss and finalize Checkpoint 2 document; complete project check-in; assign next tasks | ⏳ |\n",
    "| 3/6/2026  | 13:00 | Complete analysis;draft results, conclusion, and discussion | Progress check and peer review; discuss and edit full project | ⏳ |\n",
    "| 3/13/2026 | 13:00 | Progress on assigned tasks | Progress check and peer review | ⏳ |\n",
    "| 3/16/2026 | 13:00 | Group members finish assigned parts | Discuss final project and video; finalize team-evaluation survey | ⏳ |\n",
    "| 3/18/2026 | Before 11:59 | Video and project refined | Final project and video check; submit project on time | ⏳ |\n",
    "\n",
    "---\n",
    "\n",
    "### Role & Responsibility Matrix\n",
    "\n",
    "| # | Tasks | Lead Contributor | Backup contributor | Support | Notes for implementation|\n",
    "|---|--------------------|----------|------------|-------------|-----------|\n",
    "| 1 | Project administration & timeline tracking | Jeremy | Jerry | Everyone | Sets agendas, posts minutes, updates Kanban, reminds team of deadlines. |\n",
    "| 2 | Conceptualization & research question | Jerry | Zack | Everyone | Frames hypothesis, defines variables, keeps scope realistic. |\n",
    "| 3 | Background / related-work section | Zack | Jerry | Everyone | Gathers literature and comparable projects; drafts background text. |\n",
    "| 4 | Data sourcing & ethics checklist | Subika | Jeremy | Zack | Locates raw datasets, documents licenses/IRB issues, stores files in `/data/raw`. |\n",
    "| 5 | Data curation & wrangling notebooks | Subika | Jimmy | Jeremy | Cleans, merges, and outputs tidy `player_season.csv`. |\n",
    "| 6 | Analysis & modeling notebooks | Jerry | Subika | Jimmy | Builds regression models, checks assumptions, saves results tables/figures. |\n",
    "| 7 | Visualization (EDA + final figs) | Jimmy | Jerry | Subika | Creates clear, colour-blind-friendly plots; exports to `figs/`. |\n",
    "| 8 | Software engineering / GitOps | Jimmy | Jeremy | Everyone | Maintains repo structure, code style, CI tests, branch protection. |\n",
    "| 9 | Writing – results&discussion | Jerry | Subika | Zack | Interprets coefficients, links to background, notes limitations. |\n",
    "|10 | Writing – abstract, intro, methods | Zack | Jerry | Jeremy | Ensures consistency with background & data sections. |\n",
    "|11 | Editing & proof-reading pass | Everyone | – | – | Two-person review rule before any section is marked “Done.” |\n",
    "|12 | Video script & slide deck | Jeremy | Jimmy | Everyone | 2-min script locked by 3/13; rehearsals in 3/16 meeting. |\n",
    "|13 | Video recording & post-production | Jimmy | Jeremy | Zack | Uses OBS + iMovie/DaVinci; exports MP4 < 100 MB. |\n",
    "|14 | Final QA&submission to Gradescope | Jeremy | Jimmy | Everyone | Runs notebook end-to-end, checks links, submits by 3/18 23:59. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits\n",
    "We used AI tools to help with writing and brainstorming ideas, and to assist data wrangling for our Basketball reference dataset. All work is cross-checked by group members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
